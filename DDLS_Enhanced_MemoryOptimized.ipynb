{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# DDLS 2025 — Enhanced Diabetes Multi-Task Learning (Memory Optimized)\n",
    "\n",
    "**Author:** Argyrios Kerezis (2025) — Memory-Optimized Version  \n",
    "**⚡ Optimized for Free Google Colab (12GB RAM)**\n",
    "\n",
    "## Enhancements:\n",
    "✅ Cross-validation  \n",
    "✅ Hyperparameter tuning (reduced trials)  \n",
    "✅ SHAP analysis (optimized samples)  \n",
    "✅ Feature importance  \n",
    "✅ Calibration analysis  \n",
    "✅ Attention visualization  \n",
    "\n",
    "## Memory Optimizations:\n",
    "🔧 Reduced SHAP samples (100 instead of 1000)  \n",
    "🔧 Smaller batch sizes (512 instead of 1024)  \n",
    "🔧 Fewer Optuna trials (10 instead of 20)  \n",
    "🔧 Garbage collection between steps  \n",
    "🔧 Efficient data handling  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "memory-check",
   "metadata": {},
   "source": [
    "## 0. Memory Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89ec22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['MKL_NUM_THREADS'] = '1'\n",
    "os.environ['VECLIB_MAXIMUM_THREADS'] = '1'\n",
    "os.environ['NUMEXPR_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "check-resources",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total RAM: 1081.6 GB\n",
      "Available RAM: 852.2 GB\n",
      "GPU Available: False\n"
     ]
    }
   ],
   "source": [
    "# Check available resources\n",
    "import psutil\n",
    "import torch\n",
    "\n",
    "ram_gb = psutil.virtual_memory().total / 1e9\n",
    "print(f\"Total RAM: {ram_gb:.1f} GB\")\n",
    "print(f\"Available RAM: {psutil.virtual_memory().available / 1e9:.1f} GB\")\n",
    "print(f\"GPU Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "install-deps",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q ucimlrepo imbalanced-learn xgboost torch torchvision torchaudio \\\n",
    "    scikit-learn pandas numpy matplotlib seaborn tqdm shap optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## 2. Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports-cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, warnings, gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, f1_score, precision_score, recall_score, \n",
    "    mean_absolute_error, r2_score, roc_curve, precision_recall_curve,\n",
    "    brier_score_loss\n",
    ")\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    XGB_AVAILABLE = True\n",
    "except Exception:\n",
    "    XGB_AVAILABLE = False\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# SHAP\n",
    "import shap\n",
    "\n",
    "# Optuna\n",
    "import optuna\n",
    "from optuna.pruners import MedianPruner\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (10, 5)  # Smaller plots\n",
    "\n",
    "# Memory optimization\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-load",
   "metadata": {},
   "source": [
    "## 3. Data Loading and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dataset...\n",
      "Raw shape: (101766, 48)\n",
      "EXPLORATION : DATA QUALITY AND COMPLETENESS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      " Missing Values Summary:\n",
      "           Column  Missing_Count  Missing_Percentage Data_Type\n",
      "           weight          98569           96.858479    object\n",
      "    max_glu_serum          96420           94.746772    object\n",
      "        A1Cresult          84748           83.277322    object\n",
      "medical_specialty          49949           49.082208    object\n",
      "       payer_code          40256           39.557416    object\n",
      "             race           2273            2.233555    object\n",
      "           diag_3           1423            1.398306    object\n",
      "           diag_2            358            0.351787    object\n",
      "           diag_1             21            0.020636    object\n",
      "\n",
      "📈 Overall Missingness:\n",
      "   Total cells: 4,884,768\n",
      "   Missing cells: 374,017\n",
      "   Percentage: 7.66%\n",
      "\n",
      "✓ Saved: missing_data_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "print(\"Fetching dataset...\")\n",
    "diabetes = fetch_ucirepo(id=296)\n",
    "df = pd.concat([diabetes.data.features, diabetes.data.targets], axis=1)\n",
    "print(f\"Raw shape: {df.shape}\")\n",
    "\n",
    "\n",
    "\n",
    "# Basic cleaning\n",
    "df = df.replace(\"?\", np.nan)\n",
    "\n",
    "print(\"EXPLORATION : DATA QUALITY AND COMPLETENESS\")\n",
    "print(\"-\"*80)\n",
    "# ----------------------------------------------------------------------------\n",
    "# Calculate missing values\n",
    "# ----------------------------------------------------------------------------\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df)) * 100,\n",
    "    'Data_Type': df.dtypes\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"\\n Missing Values Summary:\")\n",
    "missing_present = missing_stats[missing_stats['Missing_Percentage'] > 0]\n",
    "if len(missing_present) > 0:\n",
    "    print(missing_present.to_string(index=False))\n",
    "else:\n",
    "    print(\"   No missing values found!\")\n",
    "\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "total_missing = df.isnull().sum().sum()\n",
    "print(f\"\\n📈 Overall Missingness:\")\n",
    "print(f\"   Total cells: {total_cells:,}\")\n",
    "print(f\"   Missing cells: {total_missing:,}\")\n",
    "print(f\"   Percentage: {total_missing/total_cells*100:.2f}%\")\n",
    "if len(missing_present) > 0:\n",
    "    plt.figure(figsize=(14, 8))\n",
    "\n",
    "    # Select top columns with missing data for visualization\n",
    "    top_missing = missing_present.head(9)['Column'].tolist()\n",
    "\n",
    "    if len(top_missing) > 0:\n",
    "        # Create binary matrix: 1 = missing, 0 = present\n",
    "        missing_matrix = df[top_missing].isnull().astype(int)\n",
    "\n",
    "        # Plot heatmap for first 500 rows\n",
    "        sns.heatmap(missing_matrix.head(500),\n",
    "                    cbar=True,\n",
    "                    yticklabels=False,\n",
    "                    cmap='RdYlGn_r',\n",
    "                    cbar_kws={'label': 'Missing (1) vs Present (0)'})\n",
    "        plt.title('Missing Data Pattern (First 500 Rows)',\n",
    "                  fontsize=14, fontweight='bold')\n",
    "        plt.xlabel('Features with Missing Data')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('missing_data_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "        print(\"\\n✓ Saved: missing_data_heatmap.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feab0347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Dataset loaded successfully!\n",
      "\n",
      " Dataset Information:\n",
      "   Total encounters: 101,766\n",
      "   Features: 48 columns\n",
      "   Target column: 'readmitted'\n",
      "   Shape: (101766, 48) (rows, columns)\n"
     ]
    }
   ],
   "source": [
    "print(\" Dataset loaded successfully!\\n\")\n",
    "print(f\" Dataset Information:\")\n",
    "print(f\"   Total encounters: {len(df):,}\")\n",
    "print(f\"   Features: {df.shape[1]} columns\")\n",
    "print(f\"   Target column: '{df.columns[-1]}'\")\n",
    "print(f\"   Shape: {df.shape} (rows, columns)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f70dbc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Dataset Metadata:\n",
      "   Repository: https://archive.ics.uci.edu/dataset/296/diabetes+130-us+hospitals+for+years+1999-2008\n",
      "   DOI: 10.24432/C5230J\n",
      "   Year: 2014\n",
      "   Instances: 101,766\n",
      "   Features: 47\n",
      "   Abstract : The dataset represents ten years (1999-2008) of clinical care at 130 US hospitals and integrated delivery networks. Each row concerns hospital records of patients diagnosed with diabetes, who underwent laboratory, medications, and stayed up to 14 days. The goal is to determine the early readmission of the patient within 30 days of discharge.\n",
      "The problem is important for the following reasons. Despite high-quality evidence showing improved clinical outcomes for diabetic patients who receive various preventive and therapeutic interventions, many patients do not receive them. This can be partially attributed to arbitrary diabetes management in hospital environments, which fail to attend to glycemic control. Failure to provide proper diabetes care not only increases the managing costs for the hospitals (as the patients are readmitted) but also impacts the morbidity and mortality of the patients, who may face complications associated with diabetes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show metadata\n",
    "print(f\"\\n Dataset Metadata:\")\n",
    "metadata = diabetes.metadata\n",
    "print(f\"   Repository: {metadata['repository_url']}\")\n",
    "print(f\"   DOI: {metadata['dataset_doi']}\")\n",
    "print(f\"   Year: {metadata['year_of_dataset_creation']}\")\n",
    "print(f\"   Instances: {metadata['num_instances']:,}\")\n",
    "print(f\"   Features: {metadata['num_features']}\")\n",
    "print(f\"   Abstract : {metadata['abstract']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845fabc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Readmission rate: 11.16%\n",
      "Avg LOS: 4.40 days\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=[c for c in [\"encounter_id\",\"patient_nbr\",\"weight\",\"payer_code\",\n",
    "                                    \"medical_specialty\",\"examide\",\"citoglipton\"] \n",
    "                      if c in df.columns])\n",
    "df[\"race\"].fillna(df[\"race\"].mode()[0], inplace=True)\n",
    "df[\"readmitted\"] = (df[\"readmitted\"] == \"<30\").astype(int)\n",
    "\n",
    "# Targets\n",
    "y_readmit = df[\"readmitted\"].astype(int)\n",
    "y_los = df[\"time_in_hospital\"].astype(float)\n",
    "\n",
    "print(f\"Readmission rate: {y_readmit.mean():.2%}\")\n",
    "print(f\"Avg LOS: {y_los.mean():.2f} days\")\n",
    "\n",
    "# Free memory\n",
    "del diabetes\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36dc531e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Feature engineering complete\n"
     ]
    }
   ],
   "source": [
    "# Clinical Risk Indices (optimized)\n",
    "def charlson(row):\n",
    "    score = 0\n",
    "    for c in [\"diag_1\", \"diag_2\", \"diag_3\"]:\n",
    "        v = str(row[c]) if c in row and pd.notna(row[c]) else \"\"\n",
    "        if v.startswith(\"250\"): score += 1\n",
    "        if v.startswith((\"410\",\"411\",\"412\",\"413\",\"414\")): score += 1\n",
    "        if v.startswith(\"428\"): score += 1\n",
    "        if v.startswith((\"582\",\"583\",\"585\",\"586\")): score += 2\n",
    "        if v.startswith((\"490\",\"491\",\"492\",\"493\",\"494\",\"495\",\"496\")): score += 1\n",
    "    return min(score, 10)\n",
    "\n",
    "def lace(row):\n",
    "    los = row.get(\"time_in_hospital\", 0.0)\n",
    "    L = 7 if los >= 14 else min(int(los), 7)\n",
    "    A = 3 if row.get(\"admission_type_id\", 3) in [1, 2] else 0\n",
    "    C = (5 if row[\"Charlson_Index\"] >= 4 else 3 if row[\"Charlson_Index\"] == 3 else \n",
    "         2 if row[\"Charlson_Index\"] == 2 else 1 if row[\"Charlson_Index\"] == 1 else 0)\n",
    "    E = 4 if row.get(\"number_emergency\", 0) >= 4 else int(row.get(\"number_emergency\", 0))\n",
    "    return L + A + C + E\n",
    "\n",
    "def hospital_score(row):\n",
    "    s = 0\n",
    "    if row.get(\"num_procedures\", 0) > 0: s += 1\n",
    "    if row.get(\"admission_type_id\", 3) in [1, 2]: s += 1\n",
    "    n_inp = row.get(\"number_inpatient\", 0)\n",
    "    if n_inp >= 5: s += 5\n",
    "    elif n_inp >= 2: s += 2\n",
    "    if row.get(\"time_in_hospital\", 0) >= 5: s += 2\n",
    "    return s\n",
    "\n",
    "df[\"Charlson_Index\"] = df.apply(charlson, axis=1)\n",
    "df[\"LACE_Index\"] = df.apply(lace, axis=1)\n",
    "df[\"HOSPITAL_Score\"] = df.apply(hospital_score, axis=1)\n",
    "df[\"Days_Since_Last_Discharge\"] = df[\"number_inpatient\"].apply(\n",
    "    lambda n: 365 if n == 0 else int(365 / (n + 1))\n",
    ")\n",
    "df[\"Polypharmacy_Count\"] = df[\"num_medications\"]\n",
    "df[\"Recent_Hosp_Count\"] = df[\"number_inpatient\"]\n",
    "\n",
    "print(\"✅ Feature engineering complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "prep-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded features: 2335\n",
      "Train: 71,236 | Val: 15,265 | Test: 15,265\n",
      "Memory: 21.6% used\n"
     ]
    }
   ],
   "source": [
    "# Prepare features\n",
    "X = df.drop(columns=[\"readmitted\", \"time_in_hospital\"])\n",
    "yR = y_readmit.copy()\n",
    "yL = y_los.copy()\n",
    "\n",
    "# One-hot encoding (memory efficient)\n",
    "X_enc = pd.get_dummies(X, drop_first=True, sparse=False)\n",
    "feature_names = X_enc.columns.tolist()\n",
    "print(f\"Encoded features: {len(feature_names)}\")\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_enc)\n",
    "\n",
    "# Splits\n",
    "X_train, X_temp, yR_train, yR_temp, yL_train, yL_temp = train_test_split(\n",
    "    X_scaled, yR, yL, test_size=0.3, stratify=yR, random_state=42\n",
    ")\n",
    "X_val, X_test, yR_val, yR_test, yL_val, yL_test = train_test_split(\n",
    "    X_temp, yR_temp, yL_temp, test_size=0.5, stratify=yR_temp, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape[0]:,} | Val: {X_val.shape[0]:,} | Test: {X_test.shape[0]:,}\")\n",
    "\n",
    "# Clean up\n",
    "del X, X_enc, df, X_scaled\n",
    "gc.collect()\n",
    "print(f\"Memory: {psutil.virtual_memory().percent:.1f}% used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baseline",
   "metadata": {},
   "source": [
    "## 4. Baseline Models (Simplified CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b9d7277",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "smote",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced: (126572, 2335) | Pos rate: 50.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMOTE with reduced neighbors (memory efficient)\n",
    "smote = SMOTE(random_state=42, k_neighbors=3)\n",
    "X_train_bal, yR_train_bal = smote.fit_resample(X_train, yR_train)\n",
    "print(f\"Balanced: {X_train_bal.shape} | Pos rate: {yR_train_bal.mean():.2%}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cv-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV: LogisticRegression...\n",
      "  AUC: 0.7106 ± 0.0012 | F1: 0.6931\n",
      "\n",
      "CV: XGBoost...\n",
      "  AUC: 0.9555 ± 0.0005 | F1: 0.9270\n",
      "\n",
      "==================================================\n",
      "                Model    CV_AUC  CV_AUC_std     CV_F1\n",
      "0  LogisticRegression  0.710593    0.001230  0.693112\n",
      "1             XGBoost  0.955466    0.000516  0.927037\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplified CV function\n",
    "# Simplified CV function (fixed to accept n_jobs)\n",
    "def quick_cv(model, X, y, name, cv=3, n_jobs=1):\n",
    "    print(f\"\\nCV: {name}...\")\n",
    "    scores = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=StratifiedKFold(n_splits=cv, shuffle=True, random_state=42),\n",
    "        scoring=['roc_auc', 'f1'],\n",
    "        n_jobs=n_jobs\n",
    "    )\n",
    "    auc_mean = scores['test_roc_auc'].mean()\n",
    "    auc_std = scores['test_roc_auc'].std()\n",
    "    f1_mean = scores['test_f1'].mean()\n",
    "    print(f\"  AUC: {auc_mean:.4f} ± {auc_std:.4f} | F1: {f1_mean:.4f}\")\n",
    "    return {'Model': name, 'CV_AUC': auc_mean, 'CV_AUC_std': auc_std, 'CV_F1': f1_mean}\n",
    "\n",
    "\n",
    "cv_results = []\n",
    "\n",
    "# Logistic Regression\n",
    "lr = LogisticRegression(max_iter=500, class_weight={0:1.0, 1:5.0}, random_state=42)\n",
    "cv_results.append(quick_cv(lr, X_train_bal, yR_train_bal, \"LogisticRegression\", n_jobs=1))\n",
    "lr.fit(X_train_bal, yR_train_bal)\n",
    "\n",
    "\"\"\"\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=80, learning_rate=0.1, max_depth=4,  # Reduced complexity\n",
    "    min_samples_split=50, min_samples_leaf=20, subsample=0.8, random_state=42\n",
    ")\n",
    "cv_results.append(quick_cv(gb, X_train_bal, yR_train_bal, \"GradientBoosting\"))\n",
    "gb.fit(X_train_bal, yR_train_bal)\n",
    "\"\"\"\n",
    "\n",
    "# XGBoost (optional)\n",
    "if XGB_AVAILABLE:\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=100, max_depth=5, learning_rate=0.05,  # Reduced\n",
    "        subsample=0.8, colsample_bytree=0.8, random_state=42, \n",
    "        tree_method=\"hist\", eval_metric=\"auc\"\n",
    "    )\n",
    "    cv_results.append(quick_cv(xgb, X_train_bal, yR_train_bal, \"XGBoost\"))\n",
    "    xgb.fit(X_train_bal, yR_train_bal)\n",
    "else:\n",
    "    xgb = None\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(pd.DataFrame(cv_results))\n",
    "print(\"=\"*50)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural",
   "metadata": {},
   "source": [
    "## 5. Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dataset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models defined\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "class MTDataset(Dataset):\n",
    "    def __init__(self, X, yR, yL):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.yR = torch.tensor(yR.values if isinstance(yR, pd.Series) else yR, dtype=torch.float32)\n",
    "        self.yL = torch.tensor(yL.values if isinstance(yL, pd.Series) else yL, dtype=torch.float32)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, i): return self.X[i], self.yR[i], self.yL[i]\n",
    "\n",
    "# MLP (smaller)\n",
    "class MultiTaskMLP(nn.Module):\n",
    "    def __init__(self, d_in, hidden=[128, 64], dropout=0.3):  # Smaller\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        d = d_in\n",
    "        for h in hidden:\n",
    "            layers += [nn.Linear(d, h), nn.BatchNorm1d(h), nn.ReLU(), nn.Dropout(dropout)]\n",
    "            d = h\n",
    "        self.encoder = nn.Sequential(*layers)\n",
    "        self.readmit_head = nn.Sequential(nn.Linear(d, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "        self.los_head = nn.Sequential(nn.Linear(d, 16), nn.ReLU(), nn.Linear(16, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        return torch.sigmoid(self.readmit_head(z)).squeeze(-1), self.los_head(z).squeeze(-1)\n",
    "\n",
    "# Transformer (smaller)\n",
    "class TransformerMultiTask(nn.Module):\n",
    "    def __init__(self, d_in, emb=64, heads=2, layers=1, dropout=0.2):  # Smaller\n",
    "        super().__init__()\n",
    "        self.proj = nn.Linear(d_in, emb)\n",
    "        enc_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=emb, nhead=heads, dim_feedforward=emb*2,\n",
    "            dropout=dropout, activation=\"gelu\", batch_first=True\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(enc_layer, num_layers=layers)\n",
    "        self.readmit_head = nn.Sequential(nn.Linear(emb, 32), nn.ReLU(), nn.Linear(32, 1))\n",
    "        self.los_head = nn.Sequential(nn.Linear(emb, 32), nn.ReLU(), nn.Linear(32, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x.unsqueeze(1))\n",
    "        z = self.encoder(x).mean(dim=1)\n",
    "        return torch.sigmoid(self.readmit_head(z)).squeeze(-1), self.los_head(z).squeeze(-1)\n",
    "\n",
    "print(\"✅ Models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optuna-section",
   "metadata": {},
   "source": [
    "## 6. Quick Hyperparameter Tuning (10 trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "optuna-mlp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:35:34,404] A new study created in memory with name: no-name-c9d0eee7-9f01-4750-8af6-b7f8946b1b12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning MLP (10 trials, fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.627595:  10%|█         | 1/10 [00:18<02:44, 18.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:35:52,693] Trial 0 finished with value: 0.6275952114130101 and parameters: {'h1': 256, 'dropout': 0.2364230622154765, 'lr': 0.00033233430210231424, 'alpha': 0.6643116219912916}. Best is trial 0 with value: 0.6275952114130101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.627595:  20%|██        | 2/10 [00:25<01:32, 11.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:35:59,586] Trial 1 finished with value: 0.6183665669260754 and parameters: {'h1': 64, 'dropout': 0.29411211243796864, 'lr': 0.0030943596195393444, 'alpha': 0.6609051364613666}. Best is trial 0 with value: 0.6275952114130101.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 2. Best value: 0.630105:  30%|███       | 3/10 [00:35<01:16, 10.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:09,795] Trial 2 finished with value: 0.6301047812821426 and parameters: {'h1': 128, 'dropout': 0.3517775505638301, 'lr': 0.0021685651138972904, 'alpha': 0.6937654078399772}. Best is trial 2 with value: 0.6301047812821426.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 3. Best value: 0.634947:  40%|████      | 4/10 [00:42<00:56,  9.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:16,664] Trial 3 finished with value: 0.6349466875979966 and parameters: {'h1': 64, 'dropout': 0.21378432678956782, 'lr': 0.002595426750351749, 'alpha': 0.7132851174197584}. Best is trial 3 with value: 0.6349466875979966.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828:  50%|█████     | 5/10 [00:52<00:47,  9.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:26,599] Trial 4 finished with value: 0.6408278901835663 and parameters: {'h1': 128, 'dropout': 0.23883908863718745, 'lr': 0.004258602660615545, 'alpha': 0.7359437706161231}. Best is trial 4 with value: 0.6408278901835663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828:  60%|██████    | 6/10 [00:58<00:34,  8.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:33,273] Trial 5 finished with value: 0.627611699249401 and parameters: {'h1': 64, 'dropout': 0.22512570717406438, 'lr': 0.004546157509060885, 'alpha': 0.6766288026173509}. Best is trial 4 with value: 0.6408278901835663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828:  70%|███████   | 7/10 [01:15<00:34, 11.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:50,375] Trial 6 finished with value: 0.6385846572936129 and parameters: {'h1': 256, 'dropout': 0.3476822310842558, 'lr': 0.0013462575451651429, 'alpha': 0.731723621387012}. Best is trial 4 with value: 0.6408278901835663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828:  80%|████████  | 8/10 [01:22<00:19,  9.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:36:57,325] Trial 7 finished with value: 0.593589027219384 and parameters: {'h1': 64, 'dropout': 0.28204548642013194, 'lr': 0.00022405371661028098, 'alpha': 0.7824070570368179}. Best is trial 4 with value: 0.6408278901835663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828:  90%|█████████ | 9/10 [01:29<00:08,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:04,200] Trial 8 finished with value: 0.6380676273060035 and parameters: {'h1': 64, 'dropout': 0.20567075190264783, 'lr': 0.003607765185598812, 'alpha': 0.7484607752883041}. Best is trial 4 with value: 0.6408278901835663.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 4. Best value: 0.640828: 100%|██████████| 10/10 [01:36<00:00,  9.67s/it]\n",
      "[I 2025-10-22 14:37:11,293] A new study created in memory with name: no-name-3f12d568-1bd1-46e4-bd8f-0d25aff67eec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:11,112] Trial 9 finished with value: 0.5198741826620317 and parameters: {'h1': 64, 'dropout': 0.25301729596612643, 'lr': 0.00015102043011252229, 'alpha': 0.6811829862617562}. Best is trial 4 with value: 0.6408278901835663.\n",
      "Best MLP AUC: 0.6408\n",
      "Best params: {'h1': 128, 'dropout': 0.23883908863718745, 'lr': 0.004258602660615545, 'alpha': 0.7359437706161231}\n",
      "\n",
      "Tuning Transformer (10 trials, fast)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  10%|█         | 1/10 [00:09<01:27,  9.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:20,986] Trial 0 finished with value: 0.6435951852748129 and parameters: {'emb': 64, 'heads': 4, 'lr': 0.0009461450381199739, 'alpha': 0.6730256237319053}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  20%|██        | 2/10 [00:19<01:16,  9.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:30,537] Trial 1 finished with value: 0.633327201243001 and parameters: {'emb': 64, 'heads': 2, 'lr': 0.00449736530729834, 'alpha': 0.6547784517393033}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  30%|███       | 3/10 [00:29<01:07,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:40,294] Trial 2 finished with value: 0.6369715107497231 and parameters: {'emb': 64, 'heads': 2, 'lr': 0.003095136226730856, 'alpha': 0.6015406627852325}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  40%|████      | 4/10 [00:45<01:14, 12.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:37:56,765] Trial 3 finished with value: 0.6084024178005625 and parameters: {'emb': 128, 'heads': 4, 'lr': 0.009955882311470116, 'alpha': 0.7882903281659157}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  50%|█████     | 5/10 [01:01<01:09, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:38:13,184] Trial 4 finished with value: 0.6222474401011184 and parameters: {'emb': 128, 'heads': 2, 'lr': 0.008561555011414684, 'alpha': 0.6959139102286446}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  60%|██████    | 6/10 [01:11<00:50, 12.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:38:23,135] Trial 5 finished with value: 0.6138793221932682 and parameters: {'emb': 64, 'heads': 4, 'lr': 0.006894793505538796, 'alpha': 0.6515961115766933}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  70%|███████   | 7/10 [01:28<00:41, 13.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:38:39,652] Trial 6 finished with value: 0.6377126627968286 and parameters: {'emb': 128, 'heads': 4, 'lr': 0.0013482640939036625, 'alpha': 0.658379734156406}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  80%|████████  | 8/10 [01:38<00:25, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:38:49,424] Trial 7 finished with value: 0.6324272942672875 and parameters: {'emb': 64, 'heads': 2, 'lr': 0.005217344679466458, 'alpha': 0.6691211571949914}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595:  90%|█████████ | 9/10 [01:54<00:13, 13.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:39:05,861] Trial 8 finished with value: 0.6390258259237602 and parameters: {'emb': 128, 'heads': 2, 'lr': 0.00044142435870714406, 'alpha': 0.7618631260846184}. Best is trial 0 with value: 0.6435951852748129.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.643595: 100%|██████████| 10/10 [02:11<00:00, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-10-22 14:39:22,466] Trial 9 finished with value: 0.637511216921765 and parameters: {'emb': 128, 'heads': 2, 'lr': 0.0003857091534851185, 'alpha': 0.675180639367784}. Best is trial 0 with value: 0.6435951852748129.\n",
      "Best Transformer AUC: 0.6436\n",
      "Best params: {'emb': 64, 'heads': 4, 'lr': 0.0009461450381199739, 'alpha': 0.6730256237319053}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Simplified Optuna (10 trials, 5 epochs)\n",
    "def quick_objective(trial, model_class, X_tr, yR_tr, yL_tr, X_v, yR_v):\n",
    "    if model_class == MultiTaskMLP:\n",
    "        hidden = [trial.suggest_categorical(\"h1\", [64, 128, 256])]\n",
    "        hidden.append(hidden[0] // 2)\n",
    "        dropout = trial.suggest_float(\"dropout\", 0.2, 0.4)\n",
    "        model = MultiTaskMLP(X_tr.shape[1], hidden=hidden, dropout=dropout)\n",
    "    else:\n",
    "        emb = trial.suggest_categorical(\"emb\", [64, 128])\n",
    "        heads = trial.suggest_categorical(\"heads\", [2, 4])\n",
    "        model = TransformerMultiTask(X_tr.shape[1], emb=emb, heads=heads, layers=1)\n",
    "    \n",
    "    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log=True)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.6, 0.8)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    tr_ds = MTDataset(X_tr, yR_tr, yL_tr)\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=512, shuffle=True)  # Smaller batch\n",
    "    \n",
    "    best_auc = 0\n",
    "    for epoch in range(5):  # Quick tuning\n",
    "        model.train()\n",
    "        for xb, yrb, ylb in tr_loader:\n",
    "            xb, yrb, ylb = xb.to(device), yrb.to(device), ylb.to(device)\n",
    "            pr, pl = model(xb)\n",
    "            loss = alpha * F.binary_cross_entropy(pr, yrb) + (1-alpha) * F.mse_loss(pl, ylb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Quick val\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            Xv_t = torch.tensor(X_v, dtype=torch.float32).to(device)\n",
    "            pr, _ = model(Xv_t)\n",
    "            auc = roc_auc_score(yR_v, pr.cpu().numpy())\n",
    "            best_auc = max(best_auc, auc)\n",
    "    \n",
    "    return best_auc\n",
    "\n",
    "# Tune MLP\n",
    "print(\"\\nTuning MLP (10 trials, fast)...\")\n",
    "study_mlp = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "study_mlp.optimize(\n",
    "    lambda t: quick_objective(t, MultiTaskMLP, X_train, yR_train, yL_train, X_val, yR_val),\n",
    "    n_trials=10, show_progress_bar=True\n",
    ")\n",
    "print(f\"Best MLP AUC: {study_mlp.best_value:.4f}\")\n",
    "print(\"Best params:\", study_mlp.best_params)\n",
    "best_mlp_params = study_mlp.best_params\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Tune Transformer\n",
    "print(\"\\nTuning Transformer (10 trials, fast)...\")\n",
    "study_trf = optuna.create_study(direction=\"maximize\", pruner=MedianPruner())\n",
    "study_trf.optimize(\n",
    "    lambda t: quick_objective(t, TransformerMultiTask, X_train, yR_train, yL_train, X_val, yR_val),\n",
    "    n_trials=10, show_progress_bar=True\n",
    ")\n",
    "print(f\"Best Transformer AUC: {study_trf.best_value:.4f}\")\n",
    "print(\"Best params:\", study_trf.best_params)\n",
    "best_trf_params = study_trf.best_params\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "train",
   "metadata": {},
   "source": [
    "## 7. Final Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "train-func",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05: AUC=0.6416 (best=0.6416), MAE=0.921\n",
      "Epoch 10: AUC=0.6343 (best=0.6416), MAE=0.901\n",
      "Epoch 15: AUC=0.6374 (best=0.6424), MAE=0.861\n",
      "Epoch 20: AUC=0.6354 (best=0.6424), MAE=0.870\n",
      "✅ mlp: Best AUC = 0.6424\n",
      "Epoch 05: AUC=0.6463 (best=0.6463), MAE=0.958\n",
      "Epoch 10: AUC=0.6401 (best=0.6463), MAE=0.903\n",
      "Epoch 15: AUC=0.6373 (best=0.6463), MAE=0.866\n",
      "Epoch 20: AUC=0.6362 (best=0.6463), MAE=0.764\n",
      "✅ transformer: Best AUC = 0.6463\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_model(model, name, Xtr, yRtr, yLtr, Xv, yRv, yLv, epochs=20, lr=1e-3, alpha=0.7):\n",
    "    tr_ds = MTDataset(Xtr, yRtr, yLtr)\n",
    "    va_ds = MTDataset(Xv, yRv, yLv)\n",
    "    tr_loader = DataLoader(tr_ds, batch_size=512, shuffle=True)  # Smaller batch\n",
    "    va_loader = DataLoader(va_ds, batch_size=512)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "    \n",
    "    best_auc, best_state = 0.0, None\n",
    "    history = {\"val_auc\": [], \"val_mae\": []}\n",
    "    \n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for xb, yrb, ylb in tr_loader:\n",
    "            xb, yrb, ylb = xb.to(device), yrb.to(device), ylb.to(device)\n",
    "            pr, pl = model(xb)\n",
    "            loss = alpha * F.binary_cross_entropy(pr, yrb) + (1-alpha) * F.mse_loss(pl, ylb)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        preds_r, preds_l, trues_r, trues_l = [], [], [], []\n",
    "        with torch.no_grad():\n",
    "            for xb, yrb, ylb in va_loader:\n",
    "                xb = xb.to(device)\n",
    "                pr, pl = model(xb)\n",
    "                preds_r.append(pr.cpu().numpy())\n",
    "                preds_l.append(pl.cpu().numpy())\n",
    "                trues_r.append(yrb.cpu().numpy())\n",
    "                trues_l.append(ylb.cpu().numpy())\n",
    "        \n",
    "        preds_r = np.concatenate(preds_r)\n",
    "        preds_l = np.concatenate(preds_l)\n",
    "        trues_r = np.concatenate(trues_r)\n",
    "        trues_l = np.concatenate(trues_l)\n",
    "        \n",
    "        auc = roc_auc_score(trues_r, preds_r)\n",
    "        mae = mean_absolute_error(trues_l, preds_l)\n",
    "        history[\"val_auc\"].append(auc)\n",
    "        history[\"val_mae\"].append(mae)\n",
    "        \n",
    "        if auc > best_auc:\n",
    "            best_auc = auc\n",
    "            best_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        \n",
    "        if ep % 5 == 0:\n",
    "            print(f\"Epoch {ep:02d}: AUC={auc:.4f} (best={best_auc:.4f}), MAE={mae:.3f}\")\n",
    "    \n",
    "    model.load_state_dict(best_state)\n",
    "    model = model.to(device)\n",
    "    torch.save(best_state, f\"best_{name}.pth\")\n",
    "    print(f\"✅ {name}: Best AUC = {best_auc:.4f}\")\n",
    "    return model, history\n",
    "\n",
    "# Build models\n",
    "mlp_hidden = [best_mlp_params.get('h1', 128), best_mlp_params.get('h1', 128)//2]\n",
    "mlp = MultiTaskMLP(X_train.shape[1], hidden=mlp_hidden, dropout=best_mlp_params.get('dropout', 0.3))\n",
    "mlp, hist_mlp = train_model(\n",
    "    mlp, \"mlp\", X_train, yR_train, yL_train, X_val, yR_val, yL_val,\n",
    "    epochs=20, lr=best_mlp_params.get('lr', 1e-3), alpha=best_mlp_params.get('alpha', 0.7)\n",
    ")\n",
    "\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "trf = TransformerMultiTask(\n",
    "    X_train.shape[1], \n",
    "    emb=best_trf_params.get('emb', 64),\n",
    "    heads=best_trf_params.get('heads', 2)\n",
    ")\n",
    "trf, hist_trf = train_model(\n",
    "    trf, \"transformer\", X_train, yR_train, yL_train, X_val, yR_val, yL_val,\n",
    "    epochs=20, lr=best_trf_params.get('lr', 1e-4), alpha=best_trf_params.get('alpha', 0.7)\n",
    ")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval",
   "metadata": {},
   "source": [
    "## 8. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eval-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Test Results\n",
      "============================================================\n",
      "             Model      AUC       F1  Precision   Recall\n",
      "           XGBoost 0.631555 0.251547   0.166603 0.513212\n",
      "    TransformerMTL 0.630118 0.249282   0.162451 0.535526\n",
      "      MultiTaskMLP 0.626966 0.247501   0.166769 0.479742\n",
      "LogisticRegression 0.611486 0.242026   0.166446 0.443335\n",
      "\n",
      "📊 LOS Results\n",
      "============================================================\n",
      "                     MAE        R2\n",
      "MultiTaskMLP    0.873441  0.783648\n",
      "TransformerMTL  0.967948  0.755812\n"
     ]
    }
   ],
   "source": [
    "# Get predictions\n",
    "lr_test = lr.predict_proba(X_test)[:, 1]\n",
    "#gb_test = gb.predict_proba(X_test)[:, 1]\n",
    "xgb_test = xgb.predict_proba(X_test)[:, 1] if xgb else None\n",
    "\n",
    "with torch.no_grad():\n",
    "    Xt = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    pr_mlp, pl_mlp = mlp(Xt)\n",
    "    pr_trf, pl_trf = trf(Xt)\n",
    "\n",
    "pr_mlp_np = pr_mlp.cpu().numpy()\n",
    "pr_trf_np = pr_trf.cpu().numpy()\n",
    "pl_mlp_np = pl_mlp.cpu().numpy()\n",
    "pl_trf_np = pl_trf.cpu().numpy()\n",
    "\n",
    "# Metrics\n",
    "def best_f1_threshold(y_true, y_score):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_score)\n",
    "    f1 = 2 * (precision * recall) / (precision + recall + 1e-10)\n",
    "    return thresholds[np.argmax(f1)], f1.max()\n",
    "\n",
    "def eval_clf(y_true, y_score, name):\n",
    "    thr, _ = best_f1_threshold(y_true, y_score)\n",
    "    y_hat = (y_score >= thr).astype(int)\n",
    "    return {\n",
    "        \"Model\": name,\n",
    "        \"AUC\": roc_auc_score(y_true, y_score),\n",
    "        \"F1\": f1_score(y_true, y_hat),\n",
    "        \"Precision\": precision_score(y_true, y_hat, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_hat)\n",
    "    }\n",
    "\n",
    "results = [\n",
    "    eval_clf(yR_test, lr_test, \"LogisticRegression\"),\n",
    "    #eval_clf(yR_test, gb_test, \"GradientBoosting\"),\n",
    "    eval_clf(yR_test, pr_mlp_np, \"MultiTaskMLP\"),\n",
    "    eval_clf(yR_test, pr_trf_np, \"TransformerMTL\")\n",
    "]\n",
    "if xgb_test is not None:\n",
    "    results.insert(2, eval_clf(yR_test, xgb_test, \"XGBoost\"))\n",
    "\n",
    "df_results = pd.DataFrame(results).sort_values(\"AUC\", ascending=False)\n",
    "print(\"\\n📊 Test Results\")\n",
    "print(\"=\"*60)\n",
    "print(df_results.to_string(index=False))\n",
    "\n",
    "# LOS\n",
    "results_los = {\n",
    "    \"MultiTaskMLP\": {\"MAE\": mean_absolute_error(yL_test, pl_mlp_np), \"R2\": r2_score(yL_test, pl_mlp_np)},\n",
    "    \"TransformerMTL\": {\"MAE\": mean_absolute_error(yL_test, pl_trf_np), \"R2\": r2_score(yL_test, pl_trf_np)}\n",
    "}\n",
    "print(\"\\n📊 LOS Results\")\n",
    "print(\"=\"*60)\n",
    "print(pd.DataFrame(results_los).T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shap",
   "metadata": {},
   "source": [
    "## 9. SHAP Analysis (Reduced Samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "shap-gb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing SHAP values (this may take 2-3 minutes)...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gb' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mComputing SHAP values (this may take 2-3 minutes)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m X_shap = X_test[:\u001b[32m100\u001b[39m]  \u001b[38;5;66;03m# Reduced\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m explainer = shap.TreeExplainer(\u001b[43mgb\u001b[49m)\n\u001b[32m      6\u001b[39m shap_values = explainer.shap_values(X_shap)\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Summary plot\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'gb' is not defined"
     ]
    }
   ],
   "source": [
    "# SHAP for GB (100 samples - memory safe)\n",
    "print(\"\\nComputing SHAP values (this may take 2-3 minutes)...\")\n",
    "X_shap = X_test[:100]  # Reduced\n",
    "\n",
    "explainer = shap.TreeExplainer(gb)\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "# Summary plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(\n",
    "    shap_values[1] if isinstance(shap_values, list) else shap_values,\n",
    "    X_shap, feature_names=feature_names, show=False, max_display=15\n",
    ")\n",
    "plt.title('SHAP Feature Importance (Top 15)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('shap_summary.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ SHAP complete\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acf6e4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admission_type_id', 'discharge_disposition_id', 'admission_source_id', 'num_lab_procedures', 'num_procedures', 'num_medications', 'number_outpatient', 'number_emergency', 'number_inpatient', 'number_diagnoses', 'Charlson_Index', 'LACE_Index', 'HOSPITAL_Score', 'Days_Since_Last_Discharge', 'Polypharmacy_Count', 'Recent_Hosp_Count', 'race_Asian', 'race_Caucasian', 'race_Hispanic', 'race_Other', 'gender_Male', 'gender_Unknown/Invalid', 'age_[10-20)', 'age_[20-30)', 'age_[30-40)', 'age_[40-50)', 'age_[50-60)', 'age_[60-70)', 'age_[70-80)', 'age_[80-90)', 'age_[90-100)', 'diag_1_11', 'diag_1_110', 'diag_1_112', 'diag_1_114', 'diag_1_115', 'diag_1_117', 'diag_1_131', 'diag_1_133', 'diag_1_135', 'diag_1_136', 'diag_1_141', 'diag_1_142', 'diag_1_143', 'diag_1_145', 'diag_1_146', 'diag_1_147', 'diag_1_148', 'diag_1_149', 'diag_1_150', 'diag_1_151', 'diag_1_152', 'diag_1_153', 'diag_1_154', 'diag_1_155', 'diag_1_156', 'diag_1_157', 'diag_1_158', 'diag_1_160', 'diag_1_161', 'diag_1_162', 'diag_1_163', 'diag_1_164', 'diag_1_170', 'diag_1_171', 'diag_1_172', 'diag_1_173', 'diag_1_174', 'diag_1_175', 'diag_1_179', 'diag_1_180', 'diag_1_182', 'diag_1_183', 'diag_1_184', 'diag_1_185', 'diag_1_187', 'diag_1_188', 'diag_1_189', 'diag_1_191', 'diag_1_192', 'diag_1_193', 'diag_1_194', 'diag_1_195', 'diag_1_196', 'diag_1_197', 'diag_1_198', 'diag_1_199', 'diag_1_200', 'diag_1_201', 'diag_1_202', 'diag_1_203', 'diag_1_204', 'diag_1_205', 'diag_1_207', 'diag_1_208', 'diag_1_210', 'diag_1_211', 'diag_1_212', 'diag_1_214', 'diag_1_215', 'diag_1_216', 'diag_1_217', 'diag_1_218', 'diag_1_219', 'diag_1_220', 'diag_1_223', 'diag_1_225', 'diag_1_226', 'diag_1_227', 'diag_1_228', 'diag_1_229', 'diag_1_23', 'diag_1_230', 'diag_1_233', 'diag_1_235', 'diag_1_236', 'diag_1_237', 'diag_1_238', 'diag_1_239', 'diag_1_240', 'diag_1_241', 'diag_1_242', 'diag_1_244', 'diag_1_245', 'diag_1_246', 'diag_1_250', 'diag_1_250.01', 'diag_1_250.02', 'diag_1_250.03', 'diag_1_250.1', 'diag_1_250.11', 'diag_1_250.12', 'diag_1_250.13', 'diag_1_250.2', 'diag_1_250.21', 'diag_1_250.22', 'diag_1_250.23', 'diag_1_250.3', 'diag_1_250.31', 'diag_1_250.32', 'diag_1_250.33', 'diag_1_250.4', 'diag_1_250.41', 'diag_1_250.42', 'diag_1_250.43', 'diag_1_250.5', 'diag_1_250.51', 'diag_1_250.52', 'diag_1_250.53', 'diag_1_250.6', 'diag_1_250.7', 'diag_1_250.8', 'diag_1_250.81', 'diag_1_250.82', 'diag_1_250.83', 'diag_1_250.9', 'diag_1_250.91', 'diag_1_250.92', 'diag_1_250.93', 'diag_1_251', 'diag_1_252', 'diag_1_253', 'diag_1_255', 'diag_1_261', 'diag_1_262', 'diag_1_263', 'diag_1_266', 'diag_1_27', 'diag_1_271', 'diag_1_272', 'diag_1_273', 'diag_1_274', 'diag_1_275', 'diag_1_276', 'diag_1_277', 'diag_1_278', 'diag_1_279', 'diag_1_280', 'diag_1_281', 'diag_1_282', 'diag_1_283', 'diag_1_284', 'diag_1_285', 'diag_1_286', 'diag_1_287', 'diag_1_288', 'diag_1_289', 'diag_1_290', 'diag_1_291', 'diag_1_292', 'diag_1_293', 'diag_1_294', 'diag_1_295', 'diag_1_296', 'diag_1_297', 'diag_1_298', 'diag_1_299', 'diag_1_3', 'diag_1_300', 'diag_1_301', 'diag_1_303', 'diag_1_304', 'diag_1_305', 'diag_1_306', 'diag_1_307', 'diag_1_308', 'diag_1_309', 'diag_1_31', 'diag_1_310', 'diag_1_311', 'diag_1_312', 'diag_1_314', 'diag_1_318', 'diag_1_320', 'diag_1_322', 'diag_1_323', 'diag_1_324', 'diag_1_325', 'diag_1_327', 'diag_1_331', 'diag_1_332', 'diag_1_333', 'diag_1_334', 'diag_1_335', 'diag_1_336', 'diag_1_337', 'diag_1_338', 'diag_1_34', 'diag_1_340', 'diag_1_341', 'diag_1_342', 'diag_1_344', 'diag_1_345', 'diag_1_346', 'diag_1_347', 'diag_1_348', 'diag_1_349', 'diag_1_35', 'diag_1_350', 'diag_1_351', 'diag_1_352', 'diag_1_353', 'diag_1_354', 'diag_1_355', 'diag_1_356', 'diag_1_357', 'diag_1_358', 'diag_1_359', 'diag_1_36', 'diag_1_360', 'diag_1_361', 'diag_1_362', 'diag_1_363', 'diag_1_365', 'diag_1_366', 'diag_1_368', 'diag_1_369', 'diag_1_370', 'diag_1_372', 'diag_1_373', 'diag_1_374', 'diag_1_375', 'diag_1_376', 'diag_1_377', 'diag_1_378', 'diag_1_379', 'diag_1_38', 'diag_1_380', 'diag_1_381', 'diag_1_382', 'diag_1_383', 'diag_1_384', 'diag_1_385', 'diag_1_386', 'diag_1_388', 'diag_1_389', 'diag_1_39', 'diag_1_391', 'diag_1_394', 'diag_1_395', 'diag_1_396', 'diag_1_397', 'diag_1_398', 'diag_1_401', 'diag_1_402', 'diag_1_403', 'diag_1_404', 'diag_1_405', 'diag_1_41', 'diag_1_410', 'diag_1_411', 'diag_1_412', 'diag_1_413', 'diag_1_414', 'diag_1_415', 'diag_1_416', 'diag_1_417', 'diag_1_42', 'diag_1_420', 'diag_1_421', 'diag_1_422', 'diag_1_423', 'diag_1_424', 'diag_1_425', 'diag_1_426', 'diag_1_427', 'diag_1_428', 'diag_1_429', 'diag_1_430', 'diag_1_431', 'diag_1_432', 'diag_1_433', 'diag_1_434', 'diag_1_435', 'diag_1_436', 'diag_1_437', 'diag_1_438', 'diag_1_440', 'diag_1_441', 'diag_1_442', 'diag_1_443', 'diag_1_444', 'diag_1_445', 'diag_1_446', 'diag_1_447', 'diag_1_448', 'diag_1_451', 'diag_1_452', 'diag_1_453', 'diag_1_454', 'diag_1_455', 'diag_1_456', 'diag_1_457', 'diag_1_458', 'diag_1_459', 'diag_1_461', 'diag_1_462', 'diag_1_463', 'diag_1_464', 'diag_1_465', 'diag_1_466', 'diag_1_47', 'diag_1_470', 'diag_1_471', 'diag_1_473', 'diag_1_474', 'diag_1_475', 'diag_1_477', 'diag_1_478', 'diag_1_48', 'diag_1_480', 'diag_1_481', 'diag_1_482', 'diag_1_483', 'diag_1_485', 'diag_1_486', 'diag_1_487', 'diag_1_49', 'diag_1_490', 'diag_1_491', 'diag_1_492', 'diag_1_493', 'diag_1_494', 'diag_1_495', 'diag_1_496', 'diag_1_5', 'diag_1_500', 'diag_1_501', 'diag_1_506', 'diag_1_507', 'diag_1_508', 'diag_1_510', 'diag_1_511', 'diag_1_512', 'diag_1_513', 'diag_1_514', 'diag_1_515', 'diag_1_516', 'diag_1_518', 'diag_1_519', 'diag_1_52', 'diag_1_521', 'diag_1_522', 'diag_1_523', 'diag_1_524', 'diag_1_526', 'diag_1_527', 'diag_1_528', 'diag_1_529', 'diag_1_53', 'diag_1_530', 'diag_1_531', 'diag_1_532', 'diag_1_533', 'diag_1_534', 'diag_1_535', 'diag_1_536', 'diag_1_537', 'diag_1_54', 'diag_1_540', 'diag_1_541', 'diag_1_542', 'diag_1_543', 'diag_1_550', 'diag_1_551', 'diag_1_552', 'diag_1_553', 'diag_1_555', 'diag_1_556', 'diag_1_557', 'diag_1_558', 'diag_1_560', 'diag_1_562', 'diag_1_564', 'diag_1_565', 'diag_1_566', 'diag_1_567', 'diag_1_568', 'diag_1_569', 'diag_1_57', 'diag_1_570', 'diag_1_571', 'diag_1_572', 'diag_1_573', 'diag_1_574', 'diag_1_575', 'diag_1_576', 'diag_1_577', 'diag_1_578', 'diag_1_579', 'diag_1_58', 'diag_1_580', 'diag_1_581', 'diag_1_582', 'diag_1_583', 'diag_1_584', 'diag_1_585', 'diag_1_586', 'diag_1_588', 'diag_1_590', 'diag_1_591', 'diag_1_592', 'diag_1_593', 'diag_1_594', 'diag_1_595', 'diag_1_596', 'diag_1_598', 'diag_1_599', 'diag_1_600', 'diag_1_601', 'diag_1_602', 'diag_1_603', 'diag_1_604', 'diag_1_605', 'diag_1_607', 'diag_1_608', 'diag_1_61', 'diag_1_610', 'diag_1_611', 'diag_1_614', 'diag_1_615', 'diag_1_616', 'diag_1_617', 'diag_1_618', 'diag_1_619', 'diag_1_620', 'diag_1_621', 'diag_1_622', 'diag_1_623', 'diag_1_625', 'diag_1_626', 'diag_1_627', 'diag_1_632', 'diag_1_633', 'diag_1_634', 'diag_1_637', 'diag_1_640', 'diag_1_641', 'diag_1_642', 'diag_1_643', 'diag_1_644', 'diag_1_645', 'diag_1_646', 'diag_1_647', 'diag_1_648', 'diag_1_649', 'diag_1_652', 'diag_1_653', 'diag_1_654', 'diag_1_655', 'diag_1_656', 'diag_1_657', 'diag_1_658', 'diag_1_659', 'diag_1_66', 'diag_1_660', 'diag_1_661', 'diag_1_663', 'diag_1_664', 'diag_1_665', 'diag_1_669', 'diag_1_671', 'diag_1_674', 'diag_1_680', 'diag_1_681', 'diag_1_682', 'diag_1_683', 'diag_1_684', 'diag_1_685', 'diag_1_686', 'diag_1_690', 'diag_1_691', 'diag_1_692', 'diag_1_693', 'diag_1_694', 'diag_1_695', 'diag_1_696', 'diag_1_698', 'diag_1_7', 'diag_1_70', 'diag_1_700', 'diag_1_703', 'diag_1_704', 'diag_1_705', 'diag_1_706', 'diag_1_707', 'diag_1_708', 'diag_1_709', 'diag_1_710', 'diag_1_711', 'diag_1_714', 'diag_1_715', 'diag_1_716', 'diag_1_717', 'diag_1_718', 'diag_1_719', 'diag_1_720', 'diag_1_721', 'diag_1_722', 'diag_1_723', 'diag_1_724', 'diag_1_725', 'diag_1_726', 'diag_1_727', 'diag_1_728', 'diag_1_729', 'diag_1_730', 'diag_1_731', 'diag_1_732', 'diag_1_733', 'diag_1_734', 'diag_1_735', 'diag_1_736', 'diag_1_737', 'diag_1_738', 'diag_1_745', 'diag_1_746', 'diag_1_747', 'diag_1_75', 'diag_1_751', 'diag_1_753', 'diag_1_756', 'diag_1_759', 'diag_1_78', 'diag_1_780', 'diag_1_781', 'diag_1_782', 'diag_1_783', 'diag_1_784', 'diag_1_785', 'diag_1_786', 'diag_1_787', 'diag_1_788', 'diag_1_789', 'diag_1_79', 'diag_1_790', 'diag_1_791', 'diag_1_792', 'diag_1_793', 'diag_1_794', 'diag_1_795', 'diag_1_796', 'diag_1_797', 'diag_1_799', 'diag_1_8', 'diag_1_800', 'diag_1_801', 'diag_1_802', 'diag_1_803', 'diag_1_804', 'diag_1_805', 'diag_1_806', 'diag_1_807', 'diag_1_808', 'diag_1_810', 'diag_1_812', 'diag_1_813', 'diag_1_814', 'diag_1_815', 'diag_1_816', 'diag_1_817', 'diag_1_82', 'diag_1_820', 'diag_1_821', 'diag_1_822', 'diag_1_823', 'diag_1_824', 'diag_1_825', 'diag_1_826', 'diag_1_827', 'diag_1_831', 'diag_1_832', 'diag_1_833', 'diag_1_834', 'diag_1_835', 'diag_1_836', 'diag_1_837', 'diag_1_838', 'diag_1_839', 'diag_1_84', 'diag_1_840', 'diag_1_842', 'diag_1_843', 'diag_1_844', 'diag_1_845', 'diag_1_846', 'diag_1_847', 'diag_1_848', 'diag_1_850', 'diag_1_851', 'diag_1_852', 'diag_1_853', 'diag_1_854', 'diag_1_860', 'diag_1_861', 'diag_1_862', 'diag_1_863', 'diag_1_864', 'diag_1_865', 'diag_1_866', 'diag_1_867', 'diag_1_868', 'diag_1_870', 'diag_1_871', 'diag_1_873', 'diag_1_875', 'diag_1_878', 'diag_1_879', 'diag_1_88', 'diag_1_880', 'diag_1_881', 'diag_1_882', 'diag_1_883', 'diag_1_885', 'diag_1_886', 'diag_1_890', 'diag_1_891', 'diag_1_892', 'diag_1_893', 'diag_1_895', 'diag_1_897', 'diag_1_9', 'diag_1_903', 'diag_1_904', 'diag_1_906', 'diag_1_911', 'diag_1_913', 'diag_1_914', 'diag_1_915', 'diag_1_916', 'diag_1_917', 'diag_1_919', 'diag_1_920', 'diag_1_921', 'diag_1_922', 'diag_1_923', 'diag_1_924', 'diag_1_928', 'diag_1_933', 'diag_1_934', 'diag_1_935', 'diag_1_936', 'diag_1_939', 'diag_1_94', 'diag_1_941', 'diag_1_942', 'diag_1_944', 'diag_1_945', 'diag_1_952', 'diag_1_955', 'diag_1_957', 'diag_1_958', 'diag_1_959', 'diag_1_962', 'diag_1_963', 'diag_1_964', 'diag_1_965', 'diag_1_966', 'diag_1_967', 'diag_1_968', 'diag_1_969', 'diag_1_97', 'diag_1_970', 'diag_1_971', 'diag_1_972', 'diag_1_973', 'diag_1_974', 'diag_1_975', 'diag_1_976', 'diag_1_977', 'diag_1_98', 'diag_1_980', 'diag_1_982', 'diag_1_983', 'diag_1_986', 'diag_1_987', 'diag_1_988', 'diag_1_989', 'diag_1_990', 'diag_1_991', 'diag_1_992', 'diag_1_994', 'diag_1_995', 'diag_1_996', 'diag_1_997', 'diag_1_998', 'diag_1_999', 'diag_1_E909', 'diag_1_V07', 'diag_1_V25', 'diag_1_V26', 'diag_1_V43', 'diag_1_V45', 'diag_1_V51', 'diag_1_V53', 'diag_1_V54', 'diag_1_V55', 'diag_1_V56', 'diag_1_V57', 'diag_1_V58', 'diag_1_V60', 'diag_1_V63', 'diag_1_V66', 'diag_1_V67', 'diag_1_V70', 'diag_1_V71', 'diag_2_110', 'diag_2_111', 'diag_2_112', 'diag_2_114', 'diag_2_115', 'diag_2_117', 'diag_2_123', 'diag_2_130', 'diag_2_131', 'diag_2_135', 'diag_2_136', 'diag_2_137', 'diag_2_138', 'diag_2_140', 'diag_2_141', 'diag_2_145', 'diag_2_150', 'diag_2_151', 'diag_2_152', 'diag_2_153', 'diag_2_154', 'diag_2_155', 'diag_2_156', 'diag_2_157', 'diag_2_162', 'diag_2_163', 'diag_2_164', 'diag_2_171', 'diag_2_172', 'diag_2_173', 'diag_2_174', 'diag_2_179', 'diag_2_180', 'diag_2_182', 'diag_2_183', 'diag_2_185', 'diag_2_186', 'diag_2_188', 'diag_2_189', 'diag_2_191', 'diag_2_192', 'diag_2_193', 'diag_2_195', 'diag_2_196', 'diag_2_197', 'diag_2_198', 'diag_2_199', 'diag_2_200', 'diag_2_201', 'diag_2_202', 'diag_2_203', 'diag_2_204', 'diag_2_205', 'diag_2_208', 'diag_2_211', 'diag_2_212', 'diag_2_214', 'diag_2_215', 'diag_2_217', 'diag_2_218', 'diag_2_220', 'diag_2_223', 'diag_2_225', 'diag_2_226', 'diag_2_227', 'diag_2_228', 'diag_2_232', 'diag_2_233', 'diag_2_235', 'diag_2_238', 'diag_2_239', 'diag_2_240', 'diag_2_241', 'diag_2_242', 'diag_2_244', 'diag_2_245', 'diag_2_246', 'diag_2_250', 'diag_2_250.01', 'diag_2_250.02', 'diag_2_250.03', 'diag_2_250.1', 'diag_2_250.11', 'diag_2_250.12', 'diag_2_250.13', 'diag_2_250.2', 'diag_2_250.21', 'diag_2_250.22', 'diag_2_250.23', 'diag_2_250.3', 'diag_2_250.31', 'diag_2_250.32', 'diag_2_250.33', 'diag_2_250.4', 'diag_2_250.41', 'diag_2_250.42', 'diag_2_250.43', 'diag_2_250.5', 'diag_2_250.51', 'diag_2_250.52', 'diag_2_250.53', 'diag_2_250.6', 'diag_2_250.7', 'diag_2_250.8', 'diag_2_250.81', 'diag_2_250.82', 'diag_2_250.83', 'diag_2_250.9', 'diag_2_250.91', 'diag_2_250.92', 'diag_2_250.93', 'diag_2_251', 'diag_2_252', 'diag_2_253', 'diag_2_255', 'diag_2_256', 'diag_2_258', 'diag_2_259', 'diag_2_260', 'diag_2_261', 'diag_2_262', 'diag_2_263', 'diag_2_266', 'diag_2_268', 'diag_2_269', 'diag_2_27', 'diag_2_270', 'diag_2_271', 'diag_2_272', 'diag_2_273', 'diag_2_274', 'diag_2_275', 'diag_2_276', 'diag_2_277', 'diag_2_278', 'diag_2_279', 'diag_2_280', 'diag_2_281', 'diag_2_282', 'diag_2_283', 'diag_2_284', 'diag_2_285', 'diag_2_286', 'diag_2_287', 'diag_2_288', 'diag_2_289', 'diag_2_290', 'diag_2_291', 'diag_2_292', 'diag_2_293', 'diag_2_294', 'diag_2_295', 'diag_2_296', 'diag_2_297', 'diag_2_298', 'diag_2_299', 'diag_2_300', 'diag_2_301', 'diag_2_302', 'diag_2_303', 'diag_2_304', 'diag_2_305', 'diag_2_306', 'diag_2_307', 'diag_2_308', 'diag_2_309', 'diag_2_31', 'diag_2_310', 'diag_2_311', 'diag_2_312', 'diag_2_314', 'diag_2_316', 'diag_2_317', 'diag_2_318', 'diag_2_319', 'diag_2_320', 'diag_2_322', 'diag_2_323', 'diag_2_324', 'diag_2_325', 'diag_2_327', 'diag_2_331', 'diag_2_332', 'diag_2_333', 'diag_2_335', 'diag_2_336', 'diag_2_337', 'diag_2_338', 'diag_2_34', 'diag_2_340', 'diag_2_341', 'diag_2_342', 'diag_2_343', 'diag_2_344', 'diag_2_345', 'diag_2_346', 'diag_2_347', 'diag_2_348', 'diag_2_349', 'diag_2_35', 'diag_2_350', 'diag_2_351', 'diag_2_352', 'diag_2_353', 'diag_2_354', 'diag_2_355', 'diag_2_356', 'diag_2_357', 'diag_2_358', 'diag_2_359', 'diag_2_360', 'diag_2_362', 'diag_2_364', 'diag_2_365', 'diag_2_366', 'diag_2_368', 'diag_2_369', 'diag_2_372', 'diag_2_373', 'diag_2_374', 'diag_2_376', 'diag_2_377', 'diag_2_378', 'diag_2_379', 'diag_2_38', 'diag_2_380', 'diag_2_381', 'diag_2_382', 'diag_2_383', 'diag_2_386', 'diag_2_388', 'diag_2_389', 'diag_2_394', 'diag_2_395', 'diag_2_396', 'diag_2_397', 'diag_2_398', 'diag_2_40', 'diag_2_401', 'diag_2_402', 'diag_2_403', 'diag_2_404', 'diag_2_405', 'diag_2_41', 'diag_2_410', 'diag_2_411', 'diag_2_412', 'diag_2_413', 'diag_2_414', 'diag_2_415', 'diag_2_416', 'diag_2_42', 'diag_2_420', 'diag_2_421', 'diag_2_422', 'diag_2_423', 'diag_2_424', 'diag_2_425', 'diag_2_426', 'diag_2_427', 'diag_2_428', 'diag_2_429', 'diag_2_430', 'diag_2_431', 'diag_2_432', 'diag_2_433', 'diag_2_434', 'diag_2_435', 'diag_2_436', 'diag_2_437', 'diag_2_438', 'diag_2_440', 'diag_2_441', 'diag_2_442', 'diag_2_443', 'diag_2_444', 'diag_2_446', 'diag_2_447', 'diag_2_448', 'diag_2_451', 'diag_2_452', 'diag_2_453', 'diag_2_454', 'diag_2_455', 'diag_2_456', 'diag_2_457', 'diag_2_458', 'diag_2_459', 'diag_2_46', 'diag_2_460', 'diag_2_461', 'diag_2_462', 'diag_2_463', 'diag_2_464', 'diag_2_465', 'diag_2_466', 'diag_2_470', 'diag_2_472', 'diag_2_473', 'diag_2_474', 'diag_2_475', 'diag_2_477', 'diag_2_478', 'diag_2_480', 'diag_2_481', 'diag_2_482', 'diag_2_483', 'diag_2_484', 'diag_2_485', 'diag_2_486', 'diag_2_487', 'diag_2_490', 'diag_2_491', 'diag_2_492', 'diag_2_493', 'diag_2_494', 'diag_2_495', 'diag_2_496', 'diag_2_5', 'diag_2_500', 'diag_2_501', 'diag_2_506', 'diag_2_507', 'diag_2_508', 'diag_2_510', 'diag_2_511', 'diag_2_512', 'diag_2_513', 'diag_2_514', 'diag_2_515', 'diag_2_516', 'diag_2_517', 'diag_2_518', 'diag_2_519', 'diag_2_52', 'diag_2_520', 'diag_2_521', 'diag_2_522', 'diag_2_523', 'diag_2_524', 'diag_2_527', 'diag_2_528', 'diag_2_529', 'diag_2_53', 'diag_2_530', 'diag_2_531', 'diag_2_532', 'diag_2_533', 'diag_2_534', 'diag_2_535', 'diag_2_536', 'diag_2_537', 'diag_2_54', 'diag_2_540', 'diag_2_542', 'diag_2_543', 'diag_2_550', 'diag_2_552', 'diag_2_553', 'diag_2_555', 'diag_2_556', 'diag_2_557', 'diag_2_558', 'diag_2_560', 'diag_2_562', 'diag_2_564', 'diag_2_565', 'diag_2_566', 'diag_2_567', 'diag_2_568', 'diag_2_569', 'diag_2_570', 'diag_2_571', 'diag_2_572', 'diag_2_573', 'diag_2_574', 'diag_2_575', 'diag_2_576', 'diag_2_577', 'diag_2_578', 'diag_2_579', 'diag_2_580', 'diag_2_581', 'diag_2_583', 'diag_2_584', 'diag_2_585', 'diag_2_586', 'diag_2_588', 'diag_2_590', 'diag_2_591', 'diag_2_592', 'diag_2_593', 'diag_2_594', 'diag_2_595', 'diag_2_596', 'diag_2_598', 'diag_2_599', 'diag_2_600', 'diag_2_601', 'diag_2_602', 'diag_2_603', 'diag_2_604', 'diag_2_605', 'diag_2_607', 'diag_2_608', 'diag_2_610', 'diag_2_611', 'diag_2_614', 'diag_2_615', 'diag_2_616', 'diag_2_617', 'diag_2_618', 'diag_2_619', 'diag_2_620', 'diag_2_621', 'diag_2_622', 'diag_2_623', 'diag_2_625', 'diag_2_626', 'diag_2_627', 'diag_2_634', 'diag_2_641', 'diag_2_642', 'diag_2_644', 'diag_2_645', 'diag_2_646', 'diag_2_647', 'diag_2_648', 'diag_2_649', 'diag_2_652', 'diag_2_654', 'diag_2_656', 'diag_2_658', 'diag_2_659', 'diag_2_66', 'diag_2_661', 'diag_2_663', 'diag_2_664', 'diag_2_665', 'diag_2_670', 'diag_2_674', 'diag_2_680', 'diag_2_681', 'diag_2_682', 'diag_2_683', 'diag_2_684', 'diag_2_685', 'diag_2_686', 'diag_2_691', 'diag_2_692', 'diag_2_693', 'diag_2_694', 'diag_2_695', 'diag_2_696', 'diag_2_698', 'diag_2_7', 'diag_2_70', 'diag_2_701', 'diag_2_702', 'diag_2_703', 'diag_2_704', 'diag_2_705', 'diag_2_706', 'diag_2_707', 'diag_2_709', 'diag_2_710', 'diag_2_711', 'diag_2_712', 'diag_2_713', 'diag_2_714', 'diag_2_715', 'diag_2_716', 'diag_2_717', 'diag_2_718', 'diag_2_719', 'diag_2_721', 'diag_2_722', 'diag_2_723', 'diag_2_724', 'diag_2_725', 'diag_2_726', 'diag_2_727', 'diag_2_728', 'diag_2_729', 'diag_2_730', 'diag_2_731', 'diag_2_733', 'diag_2_734', 'diag_2_736', 'diag_2_737', 'diag_2_738', 'diag_2_741', 'diag_2_742', 'diag_2_745', 'diag_2_746', 'diag_2_747', 'diag_2_748', 'diag_2_75', 'diag_2_750', 'diag_2_751', 'diag_2_752', 'diag_2_753', 'diag_2_754', 'diag_2_755', 'diag_2_756', 'diag_2_758', 'diag_2_759', 'diag_2_78', 'diag_2_780', 'diag_2_781', 'diag_2_782', 'diag_2_783', 'diag_2_784', 'diag_2_785', 'diag_2_786', 'diag_2_787', 'diag_2_788', 'diag_2_789', 'diag_2_79', 'diag_2_790', 'diag_2_791', 'diag_2_792', 'diag_2_793', 'diag_2_794', 'diag_2_795', 'diag_2_796', 'diag_2_797', 'diag_2_799', 'diag_2_8', 'diag_2_800', 'diag_2_801', 'diag_2_802', 'diag_2_805', 'diag_2_806', 'diag_2_807', 'diag_2_808', 'diag_2_810', 'diag_2_811', 'diag_2_812', 'diag_2_813', 'diag_2_814', 'diag_2_815', 'diag_2_816', 'diag_2_820', 'diag_2_821', 'diag_2_822', 'diag_2_823', 'diag_2_824', 'diag_2_825', 'diag_2_826', 'diag_2_831', 'diag_2_832', 'diag_2_833', 'diag_2_836', 'diag_2_837', 'diag_2_840', 'diag_2_842', 'diag_2_843', 'diag_2_844', 'diag_2_845', 'diag_2_846', 'diag_2_847', 'diag_2_850', 'diag_2_851', 'diag_2_852', 'diag_2_853', 'diag_2_860', 'diag_2_861', 'diag_2_862', 'diag_2_863', 'diag_2_864', 'diag_2_865', 'diag_2_866', 'diag_2_867', 'diag_2_868', 'diag_2_869', 'diag_2_870', 'diag_2_871', 'diag_2_872', 'diag_2_873', 'diag_2_879', 'diag_2_88', 'diag_2_880', 'diag_2_881', 'diag_2_882', 'diag_2_883', 'diag_2_884', 'diag_2_891', 'diag_2_892', 'diag_2_893', 'diag_2_894', 'diag_2_9', 'diag_2_905', 'diag_2_906', 'diag_2_907', 'diag_2_908', 'diag_2_909', 'diag_2_910', 'diag_2_911', 'diag_2_912', 'diag_2_913', 'diag_2_915', 'diag_2_916', 'diag_2_917', 'diag_2_918', 'diag_2_919', 'diag_2_920', 'diag_2_921', 'diag_2_922', 'diag_2_923', 'diag_2_924', 'diag_2_927', 'diag_2_933', 'diag_2_934', 'diag_2_94', 'diag_2_942', 'diag_2_944', 'diag_2_945', 'diag_2_947', 'diag_2_948', 'diag_2_952', 'diag_2_953', 'diag_2_955', 'diag_2_958', 'diag_2_959', 'diag_2_96', 'diag_2_962', 'diag_2_963', 'diag_2_965', 'diag_2_967', 'diag_2_968', 'diag_2_969', 'diag_2_972', 'diag_2_974', 'diag_2_975', 'diag_2_977', 'diag_2_980', 'diag_2_987', 'diag_2_989', 'diag_2_99', 'diag_2_990', 'diag_2_991', 'diag_2_992', 'diag_2_994', 'diag_2_995', 'diag_2_996', 'diag_2_997', 'diag_2_998', 'diag_2_999', 'diag_2_E812', 'diag_2_E813', 'diag_2_E814', 'diag_2_E816', 'diag_2_E817', 'diag_2_E818', 'diag_2_E819', 'diag_2_E821', 'diag_2_E826', 'diag_2_E829', 'diag_2_E849', 'diag_2_E850', 'diag_2_E853', 'diag_2_E854', 'diag_2_E858', 'diag_2_E868', 'diag_2_E870', 'diag_2_E878', 'diag_2_E879', 'diag_2_E880', 'diag_2_E881', 'diag_2_E882', 'diag_2_E883', 'diag_2_E884', 'diag_2_E885', 'diag_2_E887', 'diag_2_E888', 'diag_2_E890', 'diag_2_E900', 'diag_2_E905', 'diag_2_E906', 'diag_2_E915', 'diag_2_E916', 'diag_2_E917', 'diag_2_E918', 'diag_2_E919', 'diag_2_E924', 'diag_2_E927', 'diag_2_E928', 'diag_2_E929', 'diag_2_E930', 'diag_2_E931', 'diag_2_E932', 'diag_2_E933', 'diag_2_E934', 'diag_2_E935', 'diag_2_E936', 'diag_2_E937', 'diag_2_E938', 'diag_2_E939', 'diag_2_E941', 'diag_2_E942', 'diag_2_E944', 'diag_2_E945', 'diag_2_E947', 'diag_2_E950', 'diag_2_E965', 'diag_2_E968', 'diag_2_E980', 'diag_2_V02', 'diag_2_V03', 'diag_2_V08', 'diag_2_V09', 'diag_2_V10', 'diag_2_V11', 'diag_2_V12', 'diag_2_V13', 'diag_2_V14', 'diag_2_V15', 'diag_2_V16', 'diag_2_V17', 'diag_2_V18', 'diag_2_V23', 'diag_2_V25', 'diag_2_V42', 'diag_2_V43', 'diag_2_V44', 'diag_2_V45', 'diag_2_V46', 'diag_2_V49', 'diag_2_V50', 'diag_2_V53', 'diag_2_V54', 'diag_2_V55', 'diag_2_V57', 'diag_2_V58', 'diag_2_V60', 'diag_2_V61', 'diag_2_V62', 'diag_2_V63', 'diag_2_V64', 'diag_2_V65', 'diag_2_V66', 'diag_2_V69', 'diag_2_V70', 'diag_2_V72', 'diag_2_V85', 'diag_2_V86', 'diag_3_110', 'diag_3_111', 'diag_3_112', 'diag_3_115', 'diag_3_117', 'diag_3_122', 'diag_3_123', 'diag_3_131', 'diag_3_132', 'diag_3_135', 'diag_3_136', 'diag_3_138', 'diag_3_139', 'diag_3_14', 'diag_3_141', 'diag_3_146', 'diag_3_148', 'diag_3_150', 'diag_3_151', 'diag_3_152', 'diag_3_153', 'diag_3_154', 'diag_3_155', 'diag_3_156', 'diag_3_157', 'diag_3_158', 'diag_3_161', 'diag_3_162', 'diag_3_163', 'diag_3_164', 'diag_3_17', 'diag_3_170', 'diag_3_171', 'diag_3_172', 'diag_3_173', 'diag_3_174', 'diag_3_175', 'diag_3_179', 'diag_3_180', 'diag_3_182', 'diag_3_183', 'diag_3_185', 'diag_3_186', 'diag_3_188', 'diag_3_189', 'diag_3_191', 'diag_3_192', 'diag_3_193', 'diag_3_195', 'diag_3_196', 'diag_3_197', 'diag_3_198', 'diag_3_199', 'diag_3_200', 'diag_3_201', 'diag_3_202', 'diag_3_203', 'diag_3_204', 'diag_3_205', 'diag_3_208', 'diag_3_211', 'diag_3_214', 'diag_3_215', 'diag_3_216', 'diag_3_217', 'diag_3_218', 'diag_3_220', 'diag_3_223', 'diag_3_225', 'diag_3_226', 'diag_3_227', 'diag_3_228', 'diag_3_230', 'diag_3_233', 'diag_3_235', 'diag_3_236', 'diag_3_238', 'diag_3_239', 'diag_3_240', 'diag_3_241', 'diag_3_242', 'diag_3_243', 'diag_3_244', 'diag_3_245', 'diag_3_246', 'diag_3_250', 'diag_3_250.01', 'diag_3_250.02', 'diag_3_250.03', 'diag_3_250.1', 'diag_3_250.11', 'diag_3_250.12', 'diag_3_250.13', 'diag_3_250.2', 'diag_3_250.21', 'diag_3_250.22', 'diag_3_250.23', 'diag_3_250.3', 'diag_3_250.31', 'diag_3_250.4', 'diag_3_250.41', 'diag_3_250.42', 'diag_3_250.43', 'diag_3_250.5', 'diag_3_250.51', 'diag_3_250.52', 'diag_3_250.53', 'diag_3_250.6', 'diag_3_250.7', 'diag_3_250.8', 'diag_3_250.81', 'diag_3_250.82', 'diag_3_250.83', 'diag_3_250.9', 'diag_3_250.91', 'diag_3_250.92', 'diag_3_250.93', 'diag_3_251', 'diag_3_252', 'diag_3_253', 'diag_3_255', 'diag_3_256', 'diag_3_258', 'diag_3_259', 'diag_3_260', 'diag_3_261', 'diag_3_262', 'diag_3_263', 'diag_3_265', 'diag_3_266', 'diag_3_268', 'diag_3_27', 'diag_3_270', 'diag_3_271', 'diag_3_272', 'diag_3_273', 'diag_3_274', 'diag_3_275', 'diag_3_276', 'diag_3_277', 'diag_3_278', 'diag_3_279', 'diag_3_280', 'diag_3_281', 'diag_3_282', 'diag_3_283', 'diag_3_284', 'diag_3_285', 'diag_3_286', 'diag_3_287', 'diag_3_288', 'diag_3_289', 'diag_3_290', 'diag_3_291', 'diag_3_292', 'diag_3_293', 'diag_3_294', 'diag_3_295', 'diag_3_296', 'diag_3_297', 'diag_3_298', 'diag_3_299', 'diag_3_3', 'diag_3_300', 'diag_3_301', 'diag_3_303', 'diag_3_304', 'diag_3_305', 'diag_3_306', 'diag_3_307', 'diag_3_308', 'diag_3_309', 'diag_3_310', 'diag_3_311', 'diag_3_312', 'diag_3_313', 'diag_3_314', 'diag_3_315', 'diag_3_317', 'diag_3_318', 'diag_3_319', 'diag_3_323', 'diag_3_327', 'diag_3_331', 'diag_3_332', 'diag_3_333', 'diag_3_334', 'diag_3_335', 'diag_3_336', 'diag_3_337', 'diag_3_338', 'diag_3_34', 'diag_3_340', 'diag_3_341', 'diag_3_342', 'diag_3_343', 'diag_3_344', 'diag_3_345', 'diag_3_346', 'diag_3_347', 'diag_3_348', 'diag_3_349', 'diag_3_35', 'diag_3_350', 'diag_3_351', 'diag_3_353', 'diag_3_354', 'diag_3_355', 'diag_3_356', 'diag_3_357', 'diag_3_358', 'diag_3_359', 'diag_3_360', 'diag_3_361', 'diag_3_362', 'diag_3_365', 'diag_3_365.44', 'diag_3_366', 'diag_3_368', 'diag_3_369', 'diag_3_370', 'diag_3_372', 'diag_3_373', 'diag_3_374', 'diag_3_376', 'diag_3_377', 'diag_3_378', 'diag_3_379', 'diag_3_38', 'diag_3_380', 'diag_3_381', 'diag_3_382', 'diag_3_383', 'diag_3_384', 'diag_3_385', 'diag_3_386', 'diag_3_387', 'diag_3_388', 'diag_3_389', 'diag_3_391', 'diag_3_394', 'diag_3_395', 'diag_3_396', 'diag_3_397', 'diag_3_398', 'diag_3_401', 'diag_3_402', 'diag_3_403', 'diag_3_404', 'diag_3_405', 'diag_3_41', 'diag_3_410', 'diag_3_411', 'diag_3_412', 'diag_3_413', 'diag_3_414', 'diag_3_415', 'diag_3_416', 'diag_3_417', 'diag_3_42', 'diag_3_420', 'diag_3_421', 'diag_3_423', 'diag_3_424', 'diag_3_425', 'diag_3_426', 'diag_3_427', 'diag_3_428', 'diag_3_429', 'diag_3_430', 'diag_3_431', 'diag_3_432', 'diag_3_433', 'diag_3_434', 'diag_3_435', 'diag_3_436', 'diag_3_437', 'diag_3_438', 'diag_3_440', 'diag_3_441', 'diag_3_442', 'diag_3_443', 'diag_3_444', 'diag_3_445', 'diag_3_446', 'diag_3_447', 'diag_3_448', 'diag_3_451', 'diag_3_452', 'diag_3_453', 'diag_3_454', 'diag_3_455', 'diag_3_456', 'diag_3_457', 'diag_3_458', 'diag_3_459', 'diag_3_460', 'diag_3_461', 'diag_3_462', 'diag_3_463', 'diag_3_464', 'diag_3_465', 'diag_3_466', 'diag_3_47', 'diag_3_470', 'diag_3_472', 'diag_3_473', 'diag_3_475', 'diag_3_477', 'diag_3_478', 'diag_3_480', 'diag_3_481', 'diag_3_482', 'diag_3_483', 'diag_3_484', 'diag_3_485', 'diag_3_486', 'diag_3_487', 'diag_3_49', 'diag_3_490', 'diag_3_491', 'diag_3_492', 'diag_3_493', 'diag_3_494', 'diag_3_495', 'diag_3_496', 'diag_3_5', 'diag_3_500', 'diag_3_501', 'diag_3_506', 'diag_3_507', 'diag_3_508', 'diag_3_510', 'diag_3_511', 'diag_3_512', 'diag_3_514', 'diag_3_515', 'diag_3_516', 'diag_3_517', 'diag_3_518', 'diag_3_519', 'diag_3_521', 'diag_3_522', 'diag_3_523', 'diag_3_524', 'diag_3_525', 'diag_3_527', 'diag_3_528', 'diag_3_529', 'diag_3_53', 'diag_3_530', 'diag_3_531', 'diag_3_532', 'diag_3_533', 'diag_3_534', 'diag_3_535', 'diag_3_536', 'diag_3_537', 'diag_3_538', 'diag_3_54', 'diag_3_540', 'diag_3_542', 'diag_3_543', 'diag_3_550', 'diag_3_552', 'diag_3_553', 'diag_3_555', 'diag_3_556', 'diag_3_557', 'diag_3_558', 'diag_3_560', 'diag_3_562', 'diag_3_564', 'diag_3_565', 'diag_3_566', 'diag_3_567', 'diag_3_568', 'diag_3_569', 'diag_3_57', 'diag_3_570', 'diag_3_571', 'diag_3_572', 'diag_3_573', 'diag_3_574', 'diag_3_575', 'diag_3_576', 'diag_3_577', 'diag_3_578', 'diag_3_579', 'diag_3_580', 'diag_3_581', 'diag_3_582', 'diag_3_583', 'diag_3_584', 'diag_3_585', 'diag_3_586', 'diag_3_588', 'diag_3_590', 'diag_3_591', 'diag_3_592', 'diag_3_593', 'diag_3_594', 'diag_3_595', 'diag_3_596', 'diag_3_597', 'diag_3_598', 'diag_3_599', 'diag_3_600', 'diag_3_601', 'diag_3_602', 'diag_3_603', 'diag_3_604', 'diag_3_605', 'diag_3_607', 'diag_3_608', 'diag_3_610', 'diag_3_611', 'diag_3_614', 'diag_3_616', 'diag_3_617', 'diag_3_618', 'diag_3_619', 'diag_3_620', 'diag_3_621', 'diag_3_622', 'diag_3_623', 'diag_3_624', 'diag_3_625', 'diag_3_626', 'diag_3_627', 'diag_3_641', 'diag_3_642', 'diag_3_643', 'diag_3_644', 'diag_3_646', 'diag_3_647', 'diag_3_648', 'diag_3_649', 'diag_3_652', 'diag_3_653', 'diag_3_654', 'diag_3_655', 'diag_3_656', 'diag_3_657', 'diag_3_658', 'diag_3_659', 'diag_3_66', 'diag_3_660', 'diag_3_661', 'diag_3_663', 'diag_3_664', 'diag_3_665', 'diag_3_669', 'diag_3_670', 'diag_3_671', 'diag_3_674', 'diag_3_680', 'diag_3_681', 'diag_3_682', 'diag_3_684', 'diag_3_685', 'diag_3_686', 'diag_3_690', 'diag_3_692', 'diag_3_693', 'diag_3_694', 'diag_3_695', 'diag_3_696', 'diag_3_697', 'diag_3_698', 'diag_3_7', 'diag_3_70', 'diag_3_701', 'diag_3_702', 'diag_3_703', 'diag_3_704', 'diag_3_705', 'diag_3_706', 'diag_3_707', 'diag_3_708', 'diag_3_709', 'diag_3_710', 'diag_3_711', 'diag_3_712', 'diag_3_713', 'diag_3_714', 'diag_3_715', 'diag_3_716', 'diag_3_717', 'diag_3_718', 'diag_3_719', 'diag_3_720', 'diag_3_721', 'diag_3_722', 'diag_3_723', 'diag_3_724', 'diag_3_725', 'diag_3_726', 'diag_3_727', 'diag_3_728', 'diag_3_729', 'diag_3_730', 'diag_3_731', 'diag_3_732', 'diag_3_733', 'diag_3_734', 'diag_3_735', 'diag_3_736', 'diag_3_737', 'diag_3_738', 'diag_3_741', 'diag_3_742', 'diag_3_744', 'diag_3_745', 'diag_3_746', 'diag_3_747', 'diag_3_75', 'diag_3_750', 'diag_3_751', 'diag_3_752', 'diag_3_753', 'diag_3_754', 'diag_3_755', 'diag_3_756', 'diag_3_757', 'diag_3_758', 'diag_3_759', 'diag_3_78', 'diag_3_780', 'diag_3_781', 'diag_3_782', 'diag_3_783', 'diag_3_784', 'diag_3_785', 'diag_3_786', 'diag_3_787', 'diag_3_788', 'diag_3_789', 'diag_3_79', 'diag_3_790', 'diag_3_791', 'diag_3_792', 'diag_3_793', 'diag_3_794', 'diag_3_795', 'diag_3_796', 'diag_3_797', 'diag_3_799', 'diag_3_8', 'diag_3_800', 'diag_3_801', 'diag_3_802', 'diag_3_805', 'diag_3_807', 'diag_3_808', 'diag_3_810', 'diag_3_811', 'diag_3_812', 'diag_3_813', 'diag_3_814', 'diag_3_815', 'diag_3_816', 'diag_3_820', 'diag_3_821', 'diag_3_822', 'diag_3_823', 'diag_3_824', 'diag_3_825', 'diag_3_826', 'diag_3_831', 'diag_3_834', 'diag_3_836', 'diag_3_837', 'diag_3_838', 'diag_3_840', 'diag_3_841', 'diag_3_842', 'diag_3_844', 'diag_3_845', 'diag_3_847', 'diag_3_848', 'diag_3_850', 'diag_3_851', 'diag_3_852', 'diag_3_853', 'diag_3_854', 'diag_3_860', 'diag_3_861', 'diag_3_862', 'diag_3_863', 'diag_3_864', 'diag_3_865', 'diag_3_866', 'diag_3_867', 'diag_3_868', 'diag_3_870', 'diag_3_871', 'diag_3_872', 'diag_3_873', 'diag_3_875', 'diag_3_876', 'diag_3_877', 'diag_3_879', 'diag_3_88', 'diag_3_880', 'diag_3_881', 'diag_3_882', 'diag_3_883', 'diag_3_884', 'diag_3_890', 'diag_3_891', 'diag_3_892', 'diag_3_893', 'diag_3_9', 'diag_3_905', 'diag_3_906', 'diag_3_907', 'diag_3_908', 'diag_3_909', 'diag_3_910', 'diag_3_911', 'diag_3_912', 'diag_3_913', 'diag_3_915', 'diag_3_916', 'diag_3_917', 'diag_3_918', 'diag_3_919', 'diag_3_920', 'diag_3_921', 'diag_3_922', 'diag_3_923', 'diag_3_924', 'diag_3_928', 'diag_3_930', 'diag_3_933', 'diag_3_934', 'diag_3_935', 'diag_3_94', 'diag_3_942', 'diag_3_943', 'diag_3_944', 'diag_3_945', 'diag_3_948', 'diag_3_951', 'diag_3_952', 'diag_3_953', 'diag_3_955', 'diag_3_956', 'diag_3_958', 'diag_3_959', 'diag_3_962', 'diag_3_965', 'diag_3_966', 'diag_3_967', 'diag_3_969', 'diag_3_970', 'diag_3_971', 'diag_3_972', 'diag_3_980', 'diag_3_987', 'diag_3_989', 'diag_3_991', 'diag_3_992', 'diag_3_995', 'diag_3_996', 'diag_3_997', 'diag_3_998', 'diag_3_999', 'diag_3_E812', 'diag_3_E813', 'diag_3_E815', 'diag_3_E816', 'diag_3_E817', 'diag_3_E818', 'diag_3_E819', 'diag_3_E822', 'diag_3_E825', 'diag_3_E826', 'diag_3_E828', 'diag_3_E849', 'diag_3_E850', 'diag_3_E852', 'diag_3_E853', 'diag_3_E854', 'diag_3_E855', 'diag_3_E858', 'diag_3_E861', 'diag_3_E864', 'diag_3_E865', 'diag_3_E870', 'diag_3_E876', 'diag_3_E878', 'diag_3_E879', 'diag_3_E880', 'diag_3_E881', 'diag_3_E882', 'diag_3_E883', 'diag_3_E884', 'diag_3_E885', 'diag_3_E886', 'diag_3_E887', 'diag_3_E888', 'diag_3_E892', 'diag_3_E894', 'diag_3_E900', 'diag_3_E901', 'diag_3_E904', 'diag_3_E905', 'diag_3_E906', 'diag_3_E912', 'diag_3_E915', 'diag_3_E916', 'diag_3_E917', 'diag_3_E919', 'diag_3_E920', 'diag_3_E922', 'diag_3_E924', 'diag_3_E927', 'diag_3_E928', 'diag_3_E929', 'diag_3_E930', 'diag_3_E931', 'diag_3_E932', 'diag_3_E933', 'diag_3_E934', 'diag_3_E935', 'diag_3_E936', 'diag_3_E937', 'diag_3_E938', 'diag_3_E939', 'diag_3_E941', 'diag_3_E942', 'diag_3_E943', 'diag_3_E944', 'diag_3_E945', 'diag_3_E946', 'diag_3_E947', 'diag_3_E949', 'diag_3_E950', 'diag_3_E955', 'diag_3_E956', 'diag_3_E965', 'diag_3_E966', 'diag_3_E980', 'diag_3_E987', 'diag_3_V01', 'diag_3_V02', 'diag_3_V03', 'diag_3_V06', 'diag_3_V07', 'diag_3_V08', 'diag_3_V09', 'diag_3_V10', 'diag_3_V11', 'diag_3_V12', 'diag_3_V13', 'diag_3_V14', 'diag_3_V15', 'diag_3_V16', 'diag_3_V17', 'diag_3_V18', 'diag_3_V22', 'diag_3_V23', 'diag_3_V25', 'diag_3_V27', 'diag_3_V42', 'diag_3_V43', 'diag_3_V44', 'diag_3_V45', 'diag_3_V46', 'diag_3_V49', 'diag_3_V53', 'diag_3_V54', 'diag_3_V55', 'diag_3_V57', 'diag_3_V58', 'diag_3_V60', 'diag_3_V61', 'diag_3_V62', 'diag_3_V63', 'diag_3_V64', 'diag_3_V65', 'diag_3_V66', 'diag_3_V70', 'diag_3_V72', 'diag_3_V85', 'diag_3_V86', 'max_glu_serum_>300', 'max_glu_serum_Norm', 'A1Cresult_>8', 'A1Cresult_Norm', 'metformin_No', 'metformin_Steady', 'metformin_Up', 'repaglinide_No', 'repaglinide_Steady', 'repaglinide_Up', 'nateglinide_No', 'nateglinide_Steady', 'nateglinide_Up', 'chlorpropamide_No', 'chlorpropamide_Steady', 'chlorpropamide_Up', 'glimepiride_No', 'glimepiride_Steady', 'glimepiride_Up', 'acetohexamide_Steady', 'glipizide_No', 'glipizide_Steady', 'glipizide_Up', 'glyburide_No', 'glyburide_Steady', 'glyburide_Up', 'tolbutamide_Steady', 'pioglitazone_No', 'pioglitazone_Steady', 'pioglitazone_Up', 'rosiglitazone_No', 'rosiglitazone_Steady', 'rosiglitazone_Up', 'acarbose_No', 'acarbose_Steady', 'acarbose_Up', 'miglitol_No', 'miglitol_Steady', 'miglitol_Up', 'troglitazone_Steady', 'tolazamide_Steady', 'tolazamide_Up', 'insulin_No', 'insulin_Steady', 'insulin_Up', 'glyburide-metformin_No', 'glyburide-metformin_Steady', 'glyburide-metformin_Up', 'glipizide-metformin_Steady', 'glimepiride-pioglitazone_Steady', 'metformin-rosiglitazone_Steady', 'metformin-pioglitazone_Steady', 'change_No', 'diabetesMed_Yes']\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c421d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "COMPREHENSIVE SHAP ANALYSIS - ALL MODELS (FINAL FIX)\n",
      "======================================================================\n",
      "Analyzing 200 samples with 2335 features\n",
      "\n",
      "Found 4 models: ['LogisticRegression', 'XGBoost', 'MultiTaskMLP', 'Transformer']\n",
      "\n",
      "======================================================================\n",
      "9.1 SHAP Analysis - Logistic Regression\n",
      "======================================================================\n",
      "Computing SHAP values for Logistic Regression...\n",
      "✅ Saved: logreg_shap_importance.png\n",
      "✅ Saved: logreg_shap_effects.png\n",
      "✓ Logistic Regression SHAP completed\n",
      "\n",
      "======================================================================\n",
      "9.3 SHAP Analysis - XGBoost\n",
      "======================================================================\n",
      "Computing SHAP values for XGBoost...\n",
      "Note: Using workaround for XGBoost base_score bug...\n",
      "   → Trying alternate approach...\n",
      "   → Using KernelExplainer (slower but works)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [03:23<00:00,  2.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: xgboost_shap_importance.png\n",
      "⚠️ XGBoost SHAP failed: Feature and SHAP matrices must have the same number of rows!\n",
      "   This is likely due to XGBoost version incompatibility.\n",
      "   Skipping XGBoost SHAP analysis.\n",
      "\n",
      "======================================================================\n",
      "9.4 SHAP Analysis - MultiTaskMLP (PyTorch)\n",
      "======================================================================\n",
      "Computing SHAP values for MultiTaskMLP (2-3 minutes)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:10<00:00,  1.42s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: multitask_mlp_shap_importance.png\n",
      "✅ Saved: MultiTaskMLP_shap_effects.png\n",
      "✓ MultiTaskMLP SHAP completed\n",
      "\n",
      "======================================================================\n",
      "9.5 SHAP Analysis - Transformer (PyTorch)\n",
      "======================================================================\n",
      "Computing SHAP values for Transformer (2-3 minutes)...\n",
      "   → Detected 2 return values from Transformer\n",
      "   → Prediction function working (output shape: (2,))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:02<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved: transformer_shap_importance.png\n",
      "✅ Saved: Transformer_shap_effects.png\n",
      "✓ Transformer SHAP completed\n",
      "\n",
      "======================================================================\n",
      "9.6 Model Comparison - Feature Importance\n",
      "======================================================================\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 3 is out of bounds for axis 0 with size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 438\u001b[39m\n\u001b[32m    435\u001b[39m avg_importance = np.mean(importances_trimmed, axis=\u001b[32m0\u001b[39m)\n\u001b[32m    436\u001b[39m top_20_idx = np.argsort(avg_importance)[-\u001b[32m20\u001b[39m:]\n\u001b[32m--> \u001b[39m\u001b[32m438\u001b[39m ax = \u001b[43maxes\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_importances\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    439\u001b[39m ax.barh(\u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m), avg_importance[top_20_idx])\n\u001b[32m    440\u001b[39m ax.set_yticks(\u001b[38;5;28mrange\u001b[39m(\u001b[32m20\u001b[39m))\n",
      "\u001b[31mIndexError\u001b[39m: index 3 is out of bounds for axis 0 with size 3"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "FINAL FIXED Comprehensive SHAP Analysis for All Models\n",
    "Handles: XGBoost base_score bug, Transformer return signature, all previous issues\n",
    "\"\"\"\n",
    "\n",
    "# ============================================================================\n",
    "# SECTION 9: COMPREHENSIVE SHAP ANALYSIS (FINAL FIX)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"COMPREHENSIVE SHAP ANALYSIS - ALL MODELS (FINAL FIX)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Prepare SHAP data\n",
    "X_shap = X_test[:200]\n",
    "print(f\"Analyzing {len(X_shap)} samples with {X_test.shape[1]} features\")\n",
    "\n",
    "# Get feature names\n",
    "try:\n",
    "    feature_names = feature_names\n",
    "except:\n",
    "    feature_names = [f\"Feature_{i}\" for i in range(X_test.shape[1])]\n",
    "\n",
    "# Detect available models (flexible naming)\n",
    "available_models = {}\n",
    "\n",
    "for name in ['lr', 'logistic_regression', 'logreg']:\n",
    "    if name in globals():\n",
    "        available_models['LogisticRegression'] = globals()[name]\n",
    "        break\n",
    "\n",
    "for name in ['gb', 'gradient_boosting', 'gbc', 'gb_model']:\n",
    "    if name in globals():\n",
    "        available_models['GradientBoosting'] = globals()[name]\n",
    "        break\n",
    "\n",
    "for name in ['xgb', 'xgboost', 'xgb_model']:\n",
    "    if name in globals():\n",
    "        available_models['XGBoost'] = globals()[name]\n",
    "        break\n",
    "\n",
    "for name in ['mlp', 'multitask_mlp', 'mlp_model']:\n",
    "    if name in globals():\n",
    "        available_models['MultiTaskMLP'] = globals()[name]\n",
    "        break\n",
    "\n",
    "for name in ['trf', 'transformer', 'trf_model']:\n",
    "    if name in globals():\n",
    "        available_models['Transformer'] = globals()[name]\n",
    "        break\n",
    "\n",
    "print(f\"\\nFound {len(available_models)} models: {list(available_models.keys())}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9.1 SHAP for Logistic Regression\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9.1 SHAP Analysis - Logistic Regression\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_lr_importance = None\n",
    "\n",
    "if 'LogisticRegression' in available_models:\n",
    "    try:\n",
    "        print(\"Computing SHAP values for Logistic Regression...\")\n",
    "        lr_model = available_models['LogisticRegression']\n",
    "        \n",
    "        explainer_lr = shap.LinearExplainer(lr_model, X_train_bal[:500])\n",
    "        shap_values_lr = explainer_lr.shap_values(X_shap)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_lr,\n",
    "            X_shap,\n",
    "            feature_names=feature_names,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"Logistic Regression — Feature Importance (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"logreg_shap_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: logreg_shap_importance.png\")\n",
    "\n",
    "        # --- 2️⃣ Feature Effects (Beeswarm Plot) ---\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_lr,\n",
    "            X_shap,\n",
    "            feature_names=feature_names,\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"Logistic Regression — Feature Effects (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"logreg_shap_effects.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: logreg_shap_effects.png\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        print(\"✓ Logistic Regression SHAP completed\")\n",
    "        shap_lr_importance = np.abs(shap_values_lr).mean(0)\n",
    "        \n",
    "        del explainer_lr\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Logistic Regression SHAP failed: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ Logistic Regression model not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9.3 SHAP for XGBoost (FIXED - base_score bug workaround)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9.3 SHAP Analysis - XGBoost\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_xgb_importance = None\n",
    "\n",
    "if 'XGBoost' in available_models:\n",
    "    try:\n",
    "        print(\"Computing SHAP values for XGBoost...\")\n",
    "        xgb_model = available_models['XGBoost']\n",
    "        \n",
    "        # FIX: Work around base_score bug\n",
    "        print(\"Note: Using workaround for XGBoost base_score bug...\")\n",
    "        \n",
    "        # Try standard TreeExplainer first\n",
    "        try:\n",
    "            X_shap_float = X_shap.astype(np.float32)\n",
    "            explainer_xgb = shap.TreeExplainer(xgb_model, feature_perturbation='tree_path_dependent')\n",
    "            shap_values_xgb = explainer_xgb.shap_values(X_shap_float)\n",
    "        except:\n",
    "            # Fallback: Use model_output parameter\n",
    "            print(\"   → Trying alternate approach...\")\n",
    "            try:\n",
    "                explainer_xgb = shap.TreeExplainer(xgb_model, model_output='probability')\n",
    "                shap_values_xgb = explainer_xgb.shap_values(X_shap_float)\n",
    "            except:\n",
    "                # Final fallback: Use KernelExplainer (slow but reliable)\n",
    "                print(\"   → Using KernelExplainer (slower but works)...\")\n",
    "                explainer_xgb = shap.KernelExplainer(\n",
    "                    lambda x: xgb_model.predict_proba(x)[:, 1],\n",
    "                    X_train[:100]\n",
    "                )\n",
    "                shap_values_xgb = explainer_xgb.shap_values(X_shap[:100])\n",
    "                X_shap_float = X_shap[:100]  # Reduce to match\n",
    "\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_xgb,\n",
    "            X_shap,\n",
    "            feature_names=feature_names,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"XGBoost — Feature Importance (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"xgboost_shap_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: xgboost_shap_importance.png\")\n",
    "\n",
    "        # --- 2️⃣ Feature Effects (Beeswarm Plot) ---\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_xgb,\n",
    "            X_shap,\n",
    "            feature_names=feature_names,\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"XGBoost — Feature Effects (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"xgboost_shap_effects.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: xgb_shap_effects.png\")\n",
    "        \n",
    "      \n",
    "        \n",
    "        print(\"✓ XGBoost SHAP completed\")\n",
    "        shap_xgb_importance = np.abs(shap_values_xgb).mean(0)\n",
    "        \n",
    "        del explainer_xgb, shap_values_xgb\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ XGBoost SHAP failed: {e}\")\n",
    "        print(\"   This is likely due to XGBoost version incompatibility.\")\n",
    "        print(\"   Skipping XGBoost SHAP analysis.\")\n",
    "else:\n",
    "    print(\"⚠️ XGBoost model not found or not trained\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9.4 SHAP for MultiTaskMLP\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9.4 SHAP Analysis - MultiTaskMLP (PyTorch)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_mlp_importance = None\n",
    "\n",
    "if 'MultiTaskMLP' in available_models:\n",
    "    try:\n",
    "        print(\"Computing SHAP values for MultiTaskMLP (2-3 minutes)...\")\n",
    "        mlp_model = available_models['MultiTaskMLP']\n",
    "        \n",
    "        def mlp_predict(x):\n",
    "            mlp_model.eval()\n",
    "            with torch.no_grad():\n",
    "                if isinstance(x, np.ndarray):\n",
    "                    x = torch.FloatTensor(x).to(device)\n",
    "                readmit_logits, _ = mlp_model(x)\n",
    "                return torch.sigmoid(readmit_logits).cpu().numpy()\n",
    "        \n",
    "        explainer_mlp = shap.KernelExplainer(mlp_predict, X_train[:50])\n",
    "        shap_values_mlp = explainer_mlp.shap_values(X_shap[:50])\n",
    "\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_mlp,\n",
    "            X_shap[:50],\n",
    "            feature_names=feature_names,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"MultiTaskMLP — Feature Importance (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"multitask_mlp_shap_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: multitask_mlp_shap_importance.png\")\n",
    "\n",
    "        # --- 2️⃣ Feature Effects (Beeswarm Plot) ---\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_mlp,\n",
    "            X_shap[:50],\n",
    "            feature_names=feature_names,\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"MultiTaskMLP — Feature Effects (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"multitask_mlp_shap_effects.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: MultiTaskMLP_shap_effects.png\")\n",
    "        \n",
    "       \n",
    "        print(\"✓ MultiTaskMLP SHAP completed\")\n",
    "        shap_mlp_importance = np.abs(shap_values_mlp).mean(0)\n",
    "        \n",
    "        del explainer_mlp, shap_values_mlp\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ MultiTaskMLP SHAP failed: {e}\")\n",
    "else:\n",
    "    print(\"⚠️ MultiTaskMLP model not found\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 9.5 SHAP for Transformer (FIXED - flexible return values)\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9.5 SHAP Analysis - Transformer (PyTorch)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "shap_trf_importance = None\n",
    "\n",
    "if 'Transformer' in available_models:\n",
    "    try:\n",
    "        print(\"Computing SHAP values for Transformer (2-3 minutes)...\")\n",
    "        trf_model = available_models['Transformer']\n",
    "        \n",
    "        # FIX: Detect how many values the model returns\n",
    "        test_input = torch.FloatTensor(X_train[:1]).to(device)\n",
    "        with torch.no_grad():\n",
    "            test_output = trf_model(test_input)\n",
    "        \n",
    "        num_outputs = len(test_output) if isinstance(test_output, tuple) else 1\n",
    "        print(f\"   → Detected {num_outputs} return values from Transformer\")\n",
    "        \n",
    "        def trf_predict(x):\n",
    "            trf_model.eval()\n",
    "            with torch.no_grad():\n",
    "                if isinstance(x, np.ndarray):\n",
    "                    x = torch.FloatTensor(x).to(device)\n",
    "                \n",
    "                outputs = trf_model(x)\n",
    "                \n",
    "                # Handle different return signatures\n",
    "                if isinstance(outputs, tuple):\n",
    "                    if len(outputs) == 3:\n",
    "                        readmit_logits, _, _ = outputs\n",
    "                    elif len(outputs) == 2:\n",
    "                        readmit_logits, _ = outputs\n",
    "                    else:\n",
    "                        readmit_logits = outputs[0]\n",
    "                else:\n",
    "                    readmit_logits = outputs\n",
    "                \n",
    "                return torch.sigmoid(readmit_logits).cpu().numpy()\n",
    "        \n",
    "        # Test the predict function\n",
    "        test_pred = trf_predict(X_train[:2])\n",
    "        print(f\"   → Prediction function working (output shape: {test_pred.shape})\")\n",
    "        \n",
    "        explainer_trf = shap.KernelExplainer(trf_predict, X_train[:50])\n",
    "        shap_values_trf = explainer_trf.shap_values(X_shap[:50])\n",
    "\n",
    "\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_trf,\n",
    "            X_shap[:50],\n",
    "            feature_names=feature_names,\n",
    "            plot_type=\"bar\",\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"Transformer — Feature Importance (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"transformer_shap_importance.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: transformer_shap_importance.png\")\n",
    "\n",
    "        # --- 2️⃣ Feature Effects (Beeswarm Plot) ---\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(\n",
    "            shap_values_trf,\n",
    "            X_shap[:50],\n",
    "            feature_names=feature_names,\n",
    "            show=False,\n",
    "            max_display=20\n",
    "        )\n",
    "        plt.title(\"Transformer — Feature Effects (Top 20)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"transformer_shap_effects.png\", dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "        print(\"✅ Saved: Transformer_shap_effects.png\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "        \n",
    "        plt.sca(ax1)\n",
    "        shap.summary_plot(shap_values_trf, X_shap[:50], feature_names=feature_names, \n",
    "                          plot_type=\"bar\", show=False, max_display=20)\n",
    "        ax1.set_title(\"Transformer - Feature Importance\")\n",
    "        \n",
    "        plt.sca(ax2)\n",
    "        shap.summary_plot(shap_values_trf, X_shap[:50], feature_names=feature_names, \n",
    "                          show=False, max_display=20)\n",
    "        ax2.set_title(\"Transformer - Feature Effects\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"transformer_shap.png\", dpi=120, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"✓ Transformer SHAP completed\")\n",
    "        shap_trf_importance = np.abs(shap_values_trf).mean(0)\n",
    "        \n",
    "        del explainer_trf, shap_values_trf\n",
    "        gc.collect()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Transformer SHAP failed: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(\"⚠️ Transformer model not found\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "113299a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "9.7 Consensus Top 10 Features\n",
      "======================================================================\n",
      "\n",
      "🏆 Top 10 Most Important Features (Consensus):\n",
      "----------------------------------------------------------------------\n",
      " 1. age_[70-80)                                        | 0.0793\n",
      " 2. Days_Since_Last_Discharge                          | 0.0778\n",
      " 3. age_[80-90)                                        | 0.0599\n",
      " 4. diag_1_596                                         | 0.0553\n",
      " 5. age_[60-70)                                        | 0.0541\n",
      " 6. diag_2_E944                                        | 0.0537\n",
      " 7. diag_2_601                                         | 0.0525\n",
      " 8. diag_1_362                                         | 0.0519\n",
      " 9. diag_2_965                                         | 0.0504\n",
      "10. chlorpropamide_Up                                  | 0.0496\n",
      "\n",
      "✓ Consensus features identified\n",
      "\n",
      "======================================================================\n",
      "✅ SHAP ANALYSIS COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "📊 Successfully analyzed 3 models:\n",
      "   ✓ LogisticRegression\n",
      "   ✓ MultiTaskMLP\n",
      "   ✓ Transformer\n",
      "\n",
      "🎯 Key Deliverables:\n",
      "   • Feature importance for each model\n",
      "   • Model comparison visualizations\n",
      "   • Consensus top 10 features\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "588"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------------------------------------------\n",
    "# 9.7 Top 10 Consensus Features\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"9.7 Consensus Top 10 Features\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_importances and len(all_importances) > 0:\n",
    "    min_len = min(len(imp) for imp in all_importances.values())\n",
    "    importances_trimmed = [imp[:min_len] for imp in all_importances.values()]\n",
    "    avg_importance = np.mean(importances_trimmed, axis=0)\n",
    "    top_10_idx = np.argsort(avg_importance)[-10:][::-1]\n",
    "    \n",
    "    print(\"\\n🏆 Top 10 Most Important Features (Consensus):\")\n",
    "    print(\"-\" * 70)\n",
    "    for rank, idx in enumerate(top_10_idx, 1):\n",
    "        feature_name = feature_names[idx] if idx < len(feature_names) else f\"Feature_{idx}\"\n",
    "        importance = avg_importance[idx]\n",
    "        print(f\"{rank:2d}. {feature_name[:50]:50s} | {importance:.4f}\")\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = plt.cm.RdYlGn_r(np.linspace(0.3, 0.7, 10))\n",
    "    plt.barh(range(10), avg_importance[top_10_idx][::-1], color=colors)\n",
    "    plt.yticks(range(10), [feature_names[i][:40] if i < len(feature_names) else f\"F_{i}\" \n",
    "                            for i in top_10_idx][::-1])\n",
    "    plt.xlabel(\"Average |SHAP value| Across All Models\", fontsize=12)\n",
    "    plt.title(\"Top 10 Features - Consensus Importance\", fontsize=14, fontweight='bold')\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"top_10_features_consensus.png\", dpi=120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\n✓ Consensus features identified\")\n",
    "else:\n",
    "    print(\"⚠️ No SHAP values available\")\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# Final Summary\n",
    "# ----------------------------------------------------------------------------\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"✅ SHAP ANALYSIS COMPLETE!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "if all_importances:\n",
    "    print(f\"\\n📊 Successfully analyzed {len(all_importances)} models:\")\n",
    "    for model_name in all_importances.keys():\n",
    "        print(f\"   ✓ {model_name}\")\n",
    "    print(f\"\\n🎯 Key Deliverables:\")\n",
    "    print(f\"   • Feature importance for each model\")\n",
    "    print(f\"   • Model comparison visualizations\")\n",
    "    if len(all_importances) > 1:\n",
    "        print(f\"   • Consensus top 10 features\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n⚠️ No models were successfully analyzed\")\n",
    "    print(\"Check error messages above for details\")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature-imp",
   "metadata": {},
   "source": [
    "## 10. Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3fbc0a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All analyses complete!\n"
     ]
    }
   ],
   "source": [
    "# Calibration\n",
    "models_dict = {\n",
    "    'LR': lr_test, 'MLP': pr_mlp_np, 'TRF': pr_trf_np\n",
    "}\n",
    "if xgb_test is not None:\n",
    "    models_dict['XGB'] = xgb_test\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (name, preds) in enumerate(models_dict.items()):\n",
    "    prob_true, prob_pred = calibration_curve(yR_test, preds, n_bins=10)\n",
    "    axes[idx].plot([0, 1], [0, 1], 'k--', label='Perfect')\n",
    "    axes[idx].plot(prob_pred, prob_true, 'o-', label=name)\n",
    "    brier = brier_score_loss(yR_test, preds)\n",
    "    axes[idx].set_title(f'{name} (Brier: {brier:.3f})')\n",
    "    axes[idx].set_xlabel('Predicted')\n",
    "    axes[idx].set_ylabel('Actual')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].axis('off')\n",
    "plt.suptitle('Calibration Curves')\n",
    "plt.tight_layout()\n",
    "plt.savefig('calibration_curves.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ All analyses complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## 11. Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "save-results",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Best Model: XGBoost (AUC: 0.6316)\n",
      "\n",
      "✅ Saved:\n",
      "  - best_multitask_model.pth\n",
      "  - results.csv\n",
      "  - los_results.json\n",
      "  - hyperparameters.json\n",
      "  - shap_summary.png\n",
      "  - feature_importance.png\n",
      "  - calibration_curves.png\n",
      "\n",
      "Memory used: 21.5%\n",
      "\n",
      "🎉 Complete!\n"
     ]
    }
   ],
   "source": [
    "# Save results\n",
    "df_results.to_csv(\"results.csv\", index=False)\n",
    "with open(\"los_results.json\", \"w\") as f:\n",
    "    json.dump(results_los, f, indent=2)\n",
    "with open(\"hyperparameters.json\", \"w\") as f:\n",
    "    json.dump({\"mlp\": best_mlp_params, \"transformer\": best_trf_params}, f, indent=2)\n",
    "\n",
    "# Save best model\n",
    "winner = df_results.iloc[0]['Model']\n",
    "if winner == \"MultiTaskMLP\" and os.path.exists(\"best_mlp.pth\"):\n",
    "    os.rename(\"best_mlp.pth\", \"best_multitask_model.pth\")\n",
    "elif winner == \"TransformerMTL\" and os.path.exists(\"best_transformer.pth\"):\n",
    "    os.rename(\"best_transformer.pth\", \"best_multitask_model.pth\")\n",
    "\n",
    "print(f\"\\n🏆 Best Model: {winner} (AUC: {df_results.iloc[0]['AUC']:.4f})\")\n",
    "print(\"\\n✅ Saved:\")\n",
    "print(\"  - best_multitask_model.pth\")\n",
    "print(\"  - results.csv\")\n",
    "print(\"  - los_results.json\")\n",
    "print(\"  - hyperparameters.json\")\n",
    "print(\"  - shap_summary.png\")\n",
    "print(\"  - feature_importance.png\")\n",
    "print(\"  - calibration_curves.png\")\n",
    "\n",
    "print(f\"\\nMemory used: {psutil.virtual_memory().percent:.1f}%\")\n",
    "print(\"\\n🎉 Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
